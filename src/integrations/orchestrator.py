"""
Security Remediation Orchestrator

Koordiniert ALLE Security-Events in einem Master-Prozess um Race Conditions
und Konflikte zwischen parallelen Fixes zu vermeiden.

Workflow:
1. Sammelt alle Events in einem Zeitfenster (Batch)
2. KI erstellt einen koordinierten Gesamt-Plan
3. User Approval (einmal f√ºr den gesamten Plan)
4. Sequentielle Ausf√ºhrung mit System-Locks
5. Comprehensive Testing und Rollback bei Problemen
"""

import asyncio
import logging
import os
import time
from typing import Dict, List, Optional, Set
from dataclasses import dataclass, field
from datetime import datetime, timedelta

logger = logging.getLogger('shadowops')


@dataclass
class SecurityEventBatch:
    """Batch von Security-Events die zusammen behandelt werden"""
    events: List = field(default_factory=list)
    batch_id: str = ""
    created_at: float = 0.0
    status: str = "collecting"  # collecting, analyzing, awaiting_approval, executing, completed, failed
    status_message_id: Optional[int] = None  # Discord Message ID f√ºr Live-Updates
    status_channel_id: Optional[int] = None  # Discord Channel ID f√ºr Live-Updates

    def __post_init__(self):
        if not self.batch_id:
            self.batch_id = f"batch_{int(time.time())}"
        if not self.created_at:
            self.created_at = time.time()

    @property
    def severity_priority(self) -> int:
        """H√∂chste Severity im Batch (f√ºr Priorisierung)"""
        severity_map = {'CRITICAL': 4, 'HIGH': 3, 'MEDIUM': 2, 'LOW': 1, 'UNKNOWN': 0}
        return max([severity_map.get(e.severity, 0) for e in self.events], default=0)

    @property
    def sources(self) -> Set[str]:
        """Alle Event-Quellen im Batch"""
        return {e.source for e in self.events}

    def add_event(self, event):
        """F√ºgt Event zum Batch hinzu"""
        self.events.append(event)


@dataclass
class RemediationPlan:
    """Koordinierter Gesamt-Plan f√ºr alle Fixes"""
    batch_id: str
    description: str
    phases: List[Dict] = field(default_factory=list)
    confidence: float = 0.0
    estimated_duration_minutes: int = 0
    requires_restart: bool = False
    rollback_plan: str = ""
    ai_model: str = ""
    created_at: float = field(default_factory=time.time)


class RemediationOrchestrator:
    """
    Master Coordinator f√ºr alle Security Remediations

    Verhindert Race Conditions durch:
    - Event Batching (sammelt Events √ºber 10s)
    - Koordinierte KI-Analyse (ALLE Events zusammen)
    - Single Approval Flow
    - Sequentielle Ausf√ºhrung mit System-Locks
    """

    def __init__(self, ai_service, self_healing_coordinator, approval_manager, bot=None, discord_logger=None):
        self.ai_service = ai_service
        self.self_healing = self_healing_coordinator
        self.approval_manager = approval_manager
        self.bot = bot  # Discord Bot f√ºr Approval Messages
        self.discord_logger = discord_logger

        # Event Batching
        self.collection_window_seconds = 10  # Sammelt Events √ºber 10 Sekunden
        self.max_batch_size = 10  # Max 10 Events pro Batch (Server-Schonung)
        self.current_batch: Optional[SecurityEventBatch] = None
        self.batch_lock = asyncio.Lock()
        self.collection_task: Optional[asyncio.Task] = None

        # Execution Lock (nur 1 Remediation zur Zeit!)
        self.execution_lock = asyncio.Lock()
        self.currently_executing: Optional[str] = None

        # Batch Queue
        self.pending_batches: List[SecurityEventBatch] = []
        self.completed_batches: List[SecurityEventBatch] = []

        logger.info("üéØ Remediation Orchestrator initialisiert")
        logger.info(f"   üìä Batching Window: {self.collection_window_seconds}s")
        logger.info(f"   üì¶ Max Batch Size: {self.max_batch_size} Events (Server-Schonung)")
        logger.info("   üîí Sequential Execution Mode: ON")

    def _get_status_channel(self):
        """Holt den Status-Channel f√ºr Live-Updates"""
        if not self.bot:
            return None
        # Verwende den Approval-Channel f√ºr Live-Updates
        try:
            approval_channel_id = 1438503737315299351  # auto-remediation-approvals
            channel = self.bot.get_channel(approval_channel_id)
            return channel
        except Exception as e:
            logger.error(f"Fehler beim Holen des Status-Channels: {e}")
        return None

    async def _send_batch_status(self, batch: SecurityEventBatch, status_text: str, color: int = 0xFFAA00):
        """Sendet oder updated Status-Message f√ºr einen Batch"""
        import discord

        channel = self._get_status_channel()
        if not channel:
            logger.warning("‚ö†Ô∏è Status-Channel nicht verf√ºgbar - √ºberspringe Discord-Update")
            return

        try:
            embed = discord.Embed(
                title="üîÑ Koordinierte Remediation l√§uft",
                description=status_text,
                color=color,
                timestamp=datetime.now()
            )
            embed.set_footer(text=f"Batch ID: {batch.batch_id}")

            if batch.status_message_id:
                # Update existing message
                try:
                    message = await channel.fetch_message(batch.status_message_id)
                    await message.edit(embed=embed)
                    logger.debug(f"üìù Discord-Status updated (Message ID: {batch.status_message_id})")
                except:
                    # Message not found, send new one
                    message = await channel.send(embed=embed)
                    batch.status_message_id = message.id
                    batch.status_channel_id = channel.id
                    logger.info(f"üì§ Neue Discord-Status-Message gesendet (ID: {message.id})")
            else:
                # Send new message
                message = await channel.send(embed=embed)
                batch.status_message_id = message.id
                batch.status_channel_id = channel.id
                logger.info(f"üì§ Neue Discord-Status-Message gesendet (ID: {message.id})")

        except Exception as e:
            logger.error(f"Fehler beim Senden der Status-Message: {e}")

    async def submit_event(self, event):
        """
        Event zum Orchestrator hinzuf√ºgen

        Startet automatisch Batch-Collection wenn n√∂tig
        """
        async with self.batch_lock:
            # Erstelle neuen Batch wenn n√∂tig
            if self.current_batch is None:
                self.current_batch = SecurityEventBatch()
                logger.info(f"üì¶ Neuer Event-Batch gestartet: {self.current_batch.batch_id}")

                # Starte Collection Timer
                self.collection_task = asyncio.create_task(self._close_batch_after_timeout())

                # Sende initiale Discord-Message
                status_text = f"üì¶ **Neuer Remediation-Batch gestartet**\n\n‚è±Ô∏è Sammle Events f√ºr {self.collection_window_seconds} Sekunden..."
                await self._send_batch_status(self.current_batch, status_text, 0x3498DB)

            # F√ºge Event zum aktuellen Batch hinzu
            self.current_batch.add_event(event)
            logger.info(f"   ‚ûï Event hinzugef√ºgt: {event.source} ({event.severity})")
            logger.info(f"   üìä Batch Status: {len(self.current_batch.events)}/{self.max_batch_size} Events")

            # Check if batch size limit reached
            if len(self.current_batch.events) >= self.max_batch_size:
                logger.info(f"‚ö†Ô∏è Batch Limit erreicht ({self.max_batch_size} Events) - Schlie√üe Batch sofort")
                # Cancel collection timer and close batch immediately
                if self.collection_task:
                    self.collection_task.cancel()
                await self._close_batch_immediately()
                return

            # Update Discord-Message mit neuem Event
            event_list = "\n".join([f"‚Ä¢ **{e.source.upper()}**: {e.severity}" for e in self.current_batch.events])
            elapsed = int(time.time() - self.current_batch.created_at)
            remaining = max(0, self.collection_window_seconds - elapsed)
            status_text = f"üì¶ **Sammle Security-Events**\n\n{event_list}\n\n‚è±Ô∏è Verbleibend: **{remaining}s** | Events: **{len(self.current_batch.events)}/{self.max_batch_size}**"
            await self._send_batch_status(self.current_batch, status_text, 0x3498DB)

    async def _close_batch_after_timeout(self):
        """Schlie√üt Batch nach Collection Window mit Live-Countdown-Updates"""
        update_interval = 2  # Update Discord alle 2 Sekunden
        elapsed = 0

        batch = self.current_batch  # Referenz speichern

        while elapsed < self.collection_window_seconds:
            await asyncio.sleep(update_interval)
            elapsed += update_interval

            # Update Discord mit Countdown
            async with self.batch_lock:
                if self.current_batch == batch and len(batch.events) > 0:
                    remaining = max(0, self.collection_window_seconds - elapsed)
                    event_list = "\n".join([f"‚Ä¢ **{e.source.upper()}**: {e.severity}" for e in batch.events])

                    # Progress bar
                    progress = min(100, int((elapsed / self.collection_window_seconds) * 100))
                    bar_length = 20
                    filled = int((progress / 100) * bar_length)
                    bar = "‚ñà" * filled + "‚ñë" * (bar_length - filled)

                    status_text = f"üì¶ **Sammle Security-Events**\n\n{event_list}\n\n‚è±Ô∏è **{remaining}s** verbleibend | Events: **{len(batch.events)}**\n\n{bar} {progress}%"
                    await self._send_batch_status(batch, status_text, 0x3498DB)

        async with self.batch_lock:
            if self.current_batch and len(self.current_batch.events) > 0:
                logger.info(f"‚è∞ Batch-Collection abgelaufen ({self.collection_window_seconds}s)")
                logger.info(f"   üì¶ Batch {self.current_batch.batch_id}: {len(self.current_batch.events)} Events")
                logger.info(f"   üîç Quellen: {', '.join(self.current_batch.sources)}")

                # Final Discord Update
                event_list = "\n".join([f"‚Ä¢ **{e.source.upper()}**: {e.severity}" for e in self.current_batch.events])
                status_text = f"‚úÖ **Batch geschlossen**\n\n{event_list}\n\nüìä Total: **{len(self.current_batch.events)} Events**\nüîç Quellen: {', '.join(self.current_batch.sources)}\n\nüß† Starte KI-Analyse..."
                await self._send_batch_status(self.current_batch, status_text, 0xF39C12)

                # Batch zur Verarbeitung verschieben
                self.current_batch.status = "analyzing"
                self.pending_batches.append(self.current_batch)
                self.current_batch = None

                # Starte Verarbeitung
                asyncio.create_task(self._process_next_batch())

    async def _close_batch_immediately(self):
        """Schlie√üt Batch sofort wenn Max-Size erreicht ist (Server-Schonung)"""
        if self.current_batch and len(self.current_batch.events) > 0:
            logger.info(f"üì¶ Batch {self.current_batch.batch_id}: {len(self.current_batch.events)} Events (LIMIT)")
            logger.info(f"   üîç Quellen: {', '.join(self.current_batch.sources)}")

            # Final Discord Update
            event_list = "\n".join([f"‚Ä¢ **{e.source.upper()}**: {e.severity}" for e in self.current_batch.events])
            status_text = f"‚ö†Ô∏è **Batch Limit erreicht** ({self.max_batch_size} Events)\n\n{event_list}\n\nüìä Total: **{len(self.current_batch.events)} Events**\nüîç Quellen: {', '.join(self.current_batch.sources)}\n\nüß† Starte KI-Analyse..."
            await self._send_batch_status(self.current_batch, status_text, 0xF39C12)

            # Batch zur Verarbeitung verschieben
            self.current_batch.status = "analyzing"
            self.pending_batches.append(self.current_batch)
            self.current_batch = None

            # Starte Verarbeitung
            asyncio.create_task(self._process_next_batch())

    async def _process_next_batch(self):
        """Verarbeitet n√§chsten Batch (mit Execution Lock!)"""

        # Warte auf Execution Lock (nur 1 Remediation gleichzeitig!)
        if self.execution_lock.locked():
            logger.info("‚è≥ Execution Lock aktiv - warte auf Abschluss der laufenden Remediation...")
            return

        async with self.execution_lock:
            if not self.pending_batches:
                return

            # Hole Batch mit h√∂chster Priorit√§t
            batch = max(self.pending_batches, key=lambda b: b.severity_priority)
            self.pending_batches.remove(batch)
            self.currently_executing = batch.batch_id

            logger.info(f"üöÄ Starte koordinierte Remediation f√ºr Batch {batch.batch_id}")
            logger.info(f"   üìä {len(batch.events)} Events aus {len(batch.sources)} Quellen")

            try:
                # Phase 1: KI erstellt koordinierten Gesamt-Plan
                logger.info("üß† Phase 1: KI-Analyse aller Events...")
                plan = await self._create_coordinated_plan(batch)

                if not plan:
                    logger.error(f"‚ùå KI konnte keinen Plan erstellen f√ºr Batch {batch.batch_id}")
                    batch.status = "failed"
                    self.completed_batches.append(batch)
                    return

                logger.info(f"‚úÖ Koordinierter Plan erstellt:")
                logger.info(f"   üìù {len(plan.phases)} Phasen")
                logger.info(f"   ‚è±Ô∏è  Gesch√§tzte Dauer: {plan.estimated_duration_minutes} Minuten")
                logger.info(f"   üéØ Confidence: {plan.confidence:.0%}")

                # Phase 2: User Approval (einmal f√ºr ALLES)
                logger.info("üë§ Phase 2: Warte auf User-Approval...")
                approved = await self._request_approval(batch, plan)

                if not approved:
                    logger.warning(f"‚ùå User hat Batch {batch.batch_id} abgelehnt")
                    batch.status = "rejected"
                    self.completed_batches.append(batch)
                    return

                # Phase 3: Sequentielle Ausf√ºhrung
                logger.info("‚öôÔ∏è Phase 3: Sequentielle Ausf√ºhrung...")
                batch.status = "executing"
                success = await self._execute_plan(batch, plan)

                if success:
                    logger.info(f"‚úÖ Batch {batch.batch_id} erfolgreich abgeschlossen!")
                    batch.status = "completed"
                else:
                    logger.error(f"‚ùå Batch {batch.batch_id} fehlgeschlagen")
                    batch.status = "failed"

                self.completed_batches.append(batch)

            except Exception as e:
                logger.error(f"‚ùå Orchestrator Error f√ºr Batch {batch.batch_id}: {e}", exc_info=True)
                batch.status = "failed"
                self.completed_batches.append(batch)

            finally:
                self.currently_executing = None

                # Verarbeite n√§chsten Batch falls vorhanden
                if self.pending_batches:
                    asyncio.create_task(self._process_next_batch())

    async def _create_coordinated_plan(self, batch: SecurityEventBatch) -> Optional[RemediationPlan]:
        """
        KI erstellt koordinierten Gesamt-Plan f√ºr ALLE Events zusammen

        Wichtig: Die KI analysiert alle Events zusammen und erkennt:
        - Abh√§ngigkeiten zwischen Fixes
        - Optimale Reihenfolge
        - Gemeinsame Schritte (z.B. ein Backup f√ºr alle)
        """

        # Sende initiale Discord-Message: KI-Analyse startet
        status_text = "üß† **KI-Analyse startet**\n\nLlama3.1 analysiert alle Events und erstellt koordinierten Plan...\n\n‚è≥ Dies kann 2-3 Minuten dauern"
        await self._send_batch_status(batch, status_text, 0xF39C12)  # Orange

        # Build comprehensive context with ALL events
        context = {
            'batch_id': batch.batch_id,
            'events': [e.to_dict() for e in batch.events],
            'event_count': len(batch.events),
            'sources': list(batch.sources),
            'highest_severity': max([e.severity for e in batch.events], key=lambda s: {'CRITICAL': 4, 'HIGH': 3, 'MEDIUM': 2, 'LOW': 1}.get(s, 0)),
            'is_coordinated_planning': True  # Flag for JSON parser
        }

        # Create streaming state for live Discord updates
        streaming_state = {
            'token_count': 0,
            'last_snippet': '',
            'batch': batch,
            'start_time': time.time()
        }
        context['streaming_state'] = streaming_state

        # Special prompt for coordinated planning
        prompt = self._build_coordinated_planning_prompt(context)

        # Use AI to create coordinated plan
        logger.info("üß† Rufe KI f√ºr koordinierte Planung auf...")

        # Start background task for live Discord updates w√§hrend Streaming
        update_task = asyncio.create_task(self._stream_ai_progress_to_discord(streaming_state))

        try:
            # Use generate_coordinated_plan with coordinated planning context
            result = await self.ai_service.generate_coordinated_plan(prompt, context)

            # Stop streaming updates
            streaming_state['done'] = True
            await update_task  # Wait for final update

            if not result:
                logger.error("‚ùå KI konnte keinen koordinierten Plan erstellen")
                status_text = "‚ùå **KI-Analyse fehlgeschlagen**\n\nKonnte keinen koordinierten Plan erstellen"
                await self._send_batch_status(batch, status_text, 0xE74C3C)  # Red
                return None

            # Parse AI response into RemediationPlan
            plan = RemediationPlan(
                batch_id=batch.batch_id,
                description=result.get('description', 'Koordinierte Remediation'),
                phases=result.get('phases', []),
                confidence=result.get('confidence', 0.0),
                estimated_duration_minutes=result.get('estimated_duration_minutes', 30),
                requires_restart=result.get('requires_restart', False),
                rollback_plan=result.get('rollback_plan', 'Automatisches Rollback via Backups'),
                ai_model=result.get('ai_model', 'unknown')
            )

            # Sende finale Discord-Message: Plan erstellt
            phase_names = "\n".join([f"‚Ä¢ **Phase {i+1}**: {p['name']}" for i, p in enumerate(plan.phases)])
            status_text = f"‚úÖ **Plan erstellt**\n\n{phase_names}\n\n‚è±Ô∏è Gesch√§tzte Dauer: **{plan.estimated_duration_minutes}min**\nüéØ Confidence: **{plan.confidence:.0%}**"
            await self._send_batch_status(batch, status_text, 0x2ECC71)  # Green

            logger.info(f"‚úÖ Koordinierter Plan erstellt: {len(plan.phases)} Phasen, {plan.confidence:.0%} Confidence")
            return plan

        except Exception as e:
            # Stop streaming updates on error
            streaming_state['done'] = True
            try:
                await update_task
            except:
                pass

            logger.error(f"‚ùå Fehler bei koordinierter Planung: {e}", exc_info=True)
            status_text = f"‚ùå **KI-Analyse fehlgeschlagen**\n\nFehler: {str(e)}"
            await self._send_batch_status(batch, status_text, 0xE74C3C)  # Red
            return None

    async def _stream_ai_progress_to_discord(self, streaming_state: Dict):
        """
        Monitored streaming_state und sendet Live-Updates w√§hrend KI-Analyse
        """
        batch = streaming_state['batch']
        update_interval = 5  # Update Discord alle 5 Sekunden
        expected_tokens = 400  # Llama3.1 generiert ~400 tokens f√ºr einen Plan

        last_token_count = 0

        while not streaming_state.get('done', False):
            await asyncio.sleep(update_interval)

            token_count = streaming_state.get('token_count', 0)
            last_snippet = streaming_state.get('last_snippet', '')
            elapsed = int(time.time() - streaming_state['start_time'])

            # Nur updaten wenn neue Tokens generiert wurden
            if token_count > last_token_count:
                last_token_count = token_count

                # Progress bar basierend auf Token-Count
                progress = min(100, int((token_count / expected_tokens) * 100))
                bar_length = 20
                filled = int((progress / 100) * bar_length)
                bar = "‚ñà" * filled + "‚ñë" * (bar_length - filled)

                # Format snippet f√ºr Discord (max 100 chars)
                snippet_preview = last_snippet[:100] + "..." if len(last_snippet) > 100 else last_snippet

                # Gesch√§tzte Restzeit (basierend auf bisheriger Speed)
                if token_count > 0 and elapsed > 0:
                    tokens_per_sec = token_count / elapsed
                    remaining_tokens = max(0, expected_tokens - token_count)
                    eta_seconds = int(remaining_tokens / tokens_per_sec) if tokens_per_sec > 0 else 0
                    eta_text = f"‚è±Ô∏è ETA: ~{eta_seconds}s"
                else:
                    eta_text = "‚è±Ô∏è ETA: Berechne..."

                # Phase detection aus snippet
                phase_info = ""
                if "Phase 1" in last_snippet or "Backup" in last_snippet:
                    phase_info = "üîç Analysiere: **Phase 1 (Backup)**"
                elif "Phase 2" in last_snippet or "Docker" in last_snippet or "Update" in last_snippet:
                    phase_info = "üîç Analysiere: **Phase 2 (Updates)**"
                elif "Phase 3" in last_snippet or "trivy" in last_snippet.lower() or "Remediation" in last_snippet:
                    phase_info = "üîç Analysiere: **Phase 3 (Remediation)**"
                elif token_count > 50:
                    phase_info = "üîç Analysiere: **Sicherheitsplan**"

                status_text = f"üß† **KI-Analyse l√§uft**\n\n{phase_info}\n\nüìä Tokens: **{token_count}** / ~{expected_tokens}\n‚ö° Zeit: **{elapsed}s** | {eta_text}\n\n{bar} {progress}%"

                # F√ºge snippet hinzu falls vorhanden
                if snippet_preview:
                    status_text += f"\n\nüí¨ *\"{snippet_preview}\"*"

                await self._send_batch_status(batch, status_text, 0xF39C12)  # Orange

        # Finale Message falls noch nicht von _create_coordinated_plan() gesendet
        # (kann passieren wenn done=True gesetzt wird bevor letzte Update)

    def _build_coordinated_planning_prompt(self, context: Dict) -> str:
        """Baut Prompt f√ºr koordinierte Planung"""

        prompt = f"""# Koordinierte Security Remediation

Du bist ein Security-Engineer der einen KOORDINIERTEN Gesamt-Plan erstellt.

## Wichtig:
- Analysiere ALLE {context['event_count']} Events ZUSAMMEN
- Erkenne Abh√§ngigkeiten und Konflikte
- Erstelle EINE sequentielle Ausf√ºhrungs-Pipeline
- Vermeide Race Conditions

## Events im Batch:
"""

        for i, event in enumerate(context['events'], 1):
            prompt += f"\n### Event {i}: {event['source']} ({event['severity']})\n"
            prompt += f"```\n{event.get('details', 'N/A')}\n```\n"

        prompt += """

## Aufgabe:
Erstelle einen koordinierten Plan mit Phasen die NACHEINANDER ausgef√ºhrt werden.

**WICHTIG: Alle Texte M√úSSEN auf DEUTSCH sein!**

Ausgabe als JSON:
{
  "description": "Kurze Beschreibung des Gesamt-Plans (DEUTSCH)",
  "confidence": 0.XX,
  "estimated_duration_minutes": XX,
  "requires_restart": true/false,
  "phases": [
    {
      "name": "Phase 1: Backup",
      "description": "System-Backup erstellen",
      "steps": ["Schritt 1", "Schritt 2"],
      "estimated_minutes": 5
    },
    {
      "name": "Phase 2: Docker Updates",
      "description": "CVEs in Docker Images beheben",
      "steps": ["Update packages", "Rebuild images", "Test"],
      "estimated_minutes": 15
    }
  ],
  "rollback_plan": "Beschreibung wie Rollback funktioniert (DEUTSCH)"
}
"""

        return prompt

    async def _request_approval(self, batch: SecurityEventBatch, plan: RemediationPlan) -> bool:
        """
        Fordert User-Approval f√ºr den gesamten koordinierten Plan an

        Zeigt ein sch√∂nes Discord Embed mit:
        - Zusammenfassung aller Events
        - Alle Phasen des Plans
        - Gesch√§tzte Dauer
        - Risiko-Level
        - Approve/Reject Buttons
        """
        import discord

        logger.info(f"üë§ Fordere Approval an f√ºr Batch {batch.batch_id}")

        # Build Discord Embed
        embed = discord.Embed(
            title="üéØ Koordinierter Remediation-Plan",
            description=f"**{plan.description}**\n\nDieser Plan behandelt **{len(batch.events)} Security-Events** koordiniert und sequentiell.",
            color=discord.Color.gold(),
            timestamp=datetime.now()
        )

        # Events Summary
        sources_summary = {}
        for event in batch.events:
            source = event.source
            if source not in sources_summary:
                sources_summary[source] = {'count': 0, 'severity': event.severity}
            sources_summary[source]['count'] += 1

        events_text = "\n".join([
            f"**{source.upper()}:** {info['count']} Event(s) ({info['severity']})"
            for source, info in sources_summary.items()
        ])

        embed.add_field(
            name="üì¶ Events im Batch",
            value=events_text,
            inline=False
        )

        # Execution Plan (Phasen) - Discord Field limit: 1024 characters
        phases_text = ""
        total_minutes = 0
        max_desc_length = 120  # Max chars per phase description

        for i, phase in enumerate(plan.phases[:5], 1):  # Max 5 Phasen anzeigen
            name = phase.get('name', f'Phase {i}')
            desc = phase.get('description', 'N/A')
            minutes = phase.get('estimated_minutes', 5)
            total_minutes += minutes

            # Truncate description if too long
            if len(desc) > max_desc_length:
                desc = desc[:max_desc_length] + "..."

            phase_text = f"**{i}. {name}** (~{minutes}min)\n{desc}\n\n"

            # Check if adding this phase would exceed Discord's 1024 char limit
            if len(phases_text) + len(phase_text) > 1020:  # Leave some margin
                phases_text += f"_...und {len(plan.phases) - (i-1)} weitere Phasen_\n"
                break

            phases_text += phase_text

        if len(plan.phases) > 5 and len(phases_text) < 1020:
            phases_text += f"_...und {len(plan.phases) - 5} weitere Phasen_\n"

        # Ensure we never exceed 1024 characters (Discord limit)
        if len(phases_text) > 1024:
            phases_text = phases_text[:1020] + "..."

        embed.add_field(
            name="‚öôÔ∏è Ausf√ºhrungs-Plan",
            value=phases_text or "Keine Phasen definiert",
            inline=False
        )

        # Metadata
        confidence_color = "üü¢" if plan.confidence >= 0.8 else "üü°" if plan.confidence >= 0.6 else "üî¥"

        embed.add_field(
            name="üìä Plan-Details",
            value=f"**Confidence:** {confidence_color} {plan.confidence:.0%}\n"
                  f"**Gesch√§tzte Dauer:** ‚è±Ô∏è ~{total_minutes} Minuten\n"
                  f"**Neustart erforderlich:** {'‚úÖ Ja' if plan.requires_restart else '‚ùå Nein'}\n"
                  f"**KI-Modell:** {plan.ai_model}",
            inline=False
        )

        # Rollback Info
        if plan.rollback_plan:
            embed.add_field(
                name="üîÑ Rollback-Strategie",
                value=plan.rollback_plan[:200] + ("..." if len(plan.rollback_plan) > 200 else ""),
                inline=False
            )

        embed.set_footer(text=f"Batch ID: {batch.batch_id} | Orchestrator v1.0")

        # Send to approval channel with buttons
        try:
            if not self.bot:
                logger.warning("‚ö†Ô∏è Kein Bot verf√ºgbar f√ºr Approval - Auto-Approve")
                return True

            # Get approval channel
            approval_channel_id = 1438503737315299351  # auto-remediation-approvals
            channel = self.bot.get_channel(approval_channel_id)

            if not channel:
                logger.error(f"‚ùå Approval Channel {approval_channel_id} nicht gefunden")
                return False

            # Create approval buttons
            import discord

            class ApprovalView(discord.ui.View):
                def __init__(self, orchestrator, batch_id):
                    super().__init__(timeout=1800)  # 30 minutes
                    self.orchestrator = orchestrator
                    self.batch_id = batch_id
                    self.approved = None

                @discord.ui.button(label="‚úÖ Approve & Execute", style=discord.ButtonStyle.green, custom_id="approve")
                async def approve_button(self, interaction: discord.Interaction, button: discord.ui.Button):
                    await interaction.response.send_message(
                        f"‚úÖ **Plan approved!** Starte koordinierte Remediation...",
                        ephemeral=True
                    )
                    self.approved = True
                    self.stop()

                @discord.ui.button(label="‚ùå Reject", style=discord.ButtonStyle.red, custom_id="reject")
                async def reject_button(self, interaction: discord.Interaction, button: discord.ui.Button):
                    await interaction.response.send_message(
                        f"‚ùå **Plan abgelehnt.** Remediation wird nicht ausgef√ºhrt.",
                        ephemeral=True
                    )
                    self.approved = False
                    self.stop()

                @discord.ui.button(label="üìã Details anzeigen", style=discord.ButtonStyle.gray, custom_id="details")
                async def details_button(self, interaction: discord.Interaction, button: discord.ui.Button):
                    # Build detailed view
                    details_text = f"**Batch {self.batch_id} - Detaillierte Phasen:**\n\n"

                    # Get plan from orchestrator
                    # For now, just acknowledge
                    await interaction.response.send_message(
                        f"üìã Detaillierte Phasen-Informationen f√ºr Batch `{self.batch_id}`\n\n"
                        f"Siehe Embed oben f√ºr vollst√§ndige Details.",
                        ephemeral=True
                    )

            # Create view instance
            view = ApprovalView(self, batch.batch_id)

            # Send message with embed and buttons
            approval_message = await channel.send(embed=embed, view=view)
            logger.info(f"üì¨ Approval-Request gesendet an Channel {channel.name}")

            # Wait for user interaction
            logger.info(f"‚è≥ Warte auf User-Approval (Timeout: 30min)...")
            await view.wait()

            # Update message to show result
            if view.approved is True:
                # Update embed color to green
                embed.color = discord.Color.green()
                embed.title = "‚úÖ Plan Approved - Wird ausgef√ºhrt"
                await approval_message.edit(embed=embed, view=None)
                logger.info(f"‚úÖ Batch {batch.batch_id} wurde approved")
                return True

            elif view.approved is False:
                # Update embed color to red
                embed.color = discord.Color.red()
                embed.title = "‚ùå Plan Rejected"
                await approval_message.edit(embed=embed, view=None)
                logger.warning(f"‚ùå Batch {batch.batch_id} wurde rejected")
                return False

            else:
                # Timeout
                embed.color = discord.Color.dark_gray()
                embed.title = "‚è∞ Approval Timeout - Plan verworfen"
                await approval_message.edit(embed=embed, view=None)
                logger.warning(f"‚è∞ Batch {batch.batch_id} - Approval Timeout")
                return False

        except Exception as e:
            logger.error(f"‚ùå Fehler bei Approval-Request: {e}", exc_info=True)
            return False

    async def _execute_plan(self, batch: SecurityEventBatch, plan: RemediationPlan) -> bool:
        """
        F√ºhrt Plan sequentiell Phase f√ºr Phase aus

        Workflow:
        1. Erstelle System-Backup
        2. F√ºhre jede Phase nacheinander aus
        3. Teste nach jeder Phase
        4. Bei Fehler: Rollback und Stop
        5. Sende Discord-Updates w√§hrend Ausf√ºhrung
        """
        import discord
        from datetime import datetime

        logger.info(f"‚öôÔ∏è Starte sequentielle Ausf√ºhrung von {len(plan.phases)} Phasen")

        # Track execution start time for duration calculation
        self._execution_start_time = datetime.now()

        # Get execution channel for live updates
        execution_channel = None
        if self.bot:
            try:
                # Send to remediation-alerts channel for live updates
                channel_id = 1438503736220586164  # auto-remediation-alerts
                execution_channel = self.bot.get_channel(channel_id)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Konnte Execution-Channel nicht laden: {e}")

        # Create execution status embed
        exec_embed = None
        exec_message = None

        if execution_channel:
            exec_embed = discord.Embed(
                title="‚öôÔ∏è Koordinierte Remediation l√§uft",
                description=f"**Batch {batch.batch_id}**\n{plan.description}",
                color=discord.Color.blue(),
                timestamp=datetime.now()
            )
            exec_embed.add_field(
                name="üìä Status",
                value="üîÑ Starte Ausf√ºhrung...",
                inline=False
            )
            exec_message = await execution_channel.send(embed=exec_embed)

        # Track execution results
        executed_phases = []
        backup_created = False
        backup_path = None

        try:
            # Phase 0: Create system backup
            logger.info("üíæ Phase 0: Erstelle System-Backup...")
            if exec_message:
                exec_embed.set_field_at(
                    0,
                    name="üìä Status",
                    value="üíæ Phase 0/0: System-Backup wird erstellt...",
                    inline=False
                )
                await exec_message.edit(embed=exec_embed)

            # Create backup using BackupManager from self_healing
            backup_manager = self.self_healing.backup_manager
            backup_metadata = []

            # Collect files to backup based on events
            files_to_backup = set()
            for event in batch.events:
                if event.source == 'trivy':
                    # Backup Docker-related files
                    files_to_backup.add('/home/cmdshadow/shadowops-bot/package.json')
                    files_to_backup.add('/home/cmdshadow/shadowops-bot/Dockerfile')
                elif event.source in ['fail2ban', 'crowdsec']:
                    # Backup firewall configs
                    files_to_backup.add('/etc/fail2ban/jail.local')
                    files_to_backup.add('/etc/ufw/user.rules')
                elif event.source == 'aide':
                    # Backup will be handled by AIDE fixer
                    pass

            # Create backups
            for file_path in files_to_backup:
                if os.path.exists(file_path):
                    try:
                        backup = await backup_manager.create_backup(
                            file_path,
                            metadata={'batch_id': batch.batch_id}
                        )
                        backup_metadata.append(backup)
                        logger.info(f"   üíæ Backed up: {file_path}")
                    except Exception as e:
                        logger.warning(f"   ‚ö†Ô∏è Could not backup {file_path}: {e}")

            backup_created = len(backup_metadata) > 0
            backup_path = f"Batch {batch.batch_id} - {len(backup_metadata)} backups created"
            logger.info(f"‚úÖ Backup Phase abgeschlossen: {len(backup_metadata)} Dateien gesichert")

            # Execute each phase sequentially
            for phase_idx, phase in enumerate(plan.phases, 1):
                phase_name = phase.get('name', f'Phase {phase_idx}')
                phase_desc = phase.get('description', '')
                phase_steps = phase.get('steps', [])

                logger.info(f"üîß Phase {phase_idx}/{len(plan.phases)}: {phase_name}")
                logger.info(f"   üìù {phase_desc}")
                logger.info(f"   üìã {len(phase_steps)} Schritte")

                # Update Discord
                if exec_message:
                    progress_bar = self._create_progress_bar(phase_idx, len(plan.phases))
                    exec_embed.set_field_at(
                        0,
                        name="üìä Status",
                        value=f"üîß Phase {phase_idx}/{len(plan.phases)}: {phase_name}\n{progress_bar}\n\n{phase_desc}",
                        inline=False
                    )
                    await exec_message.edit(embed=exec_embed)

                # Execute phase steps (pass Discord message for live updates)
                phase_success = await self._execute_phase(
                    phase,
                    batch.events,
                    exec_message=exec_message,
                    exec_embed=exec_embed
                )

                if phase_success:
                    logger.info(f"‚úÖ Phase {phase_idx} erfolgreich")
                    executed_phases.append({
                        'phase': phase_name,
                        'status': 'success',
                        'index': phase_idx
                    })
                else:
                    logger.error(f"‚ùå Phase {phase_idx} fehlgeschlagen!")
                    executed_phases.append({
                        'phase': phase_name,
                        'status': 'failed',
                        'index': phase_idx
                    })

                    # Rollback on failure
                    if exec_message:
                        exec_embed.color = discord.Color.red()
                        exec_embed.set_field_at(
                            0,
                            name="üìä Status",
                            value=f"‚ùå Phase {phase_idx} fehlgeschlagen!\nüîÑ Starte Rollback...",
                            inline=False
                        )
                        await exec_message.edit(embed=exec_embed)

                    await self._rollback(backup_metadata, executed_phases, exec_message, exec_embed)
                    return False

            # All phases successful!
            logger.info(f"‚úÖ Alle {len(plan.phases)} Phasen erfolgreich ausgef√ºhrt")

            # Calculate execution duration
            if hasattr(self, '_execution_start_time'):
                duration = (datetime.now() - self._execution_start_time).total_seconds()
                duration_str = f"{int(duration // 60)}m {int(duration % 60)}s"
            else:
                duration_str = "Unknown"

            # Build detailed final summary
            final_summary = await self._build_final_summary(
                plan=plan,
                batch=batch,
                executed_phases=executed_phases,
                backup_count=len(backup_metadata),
                duration=duration_str
            )

            # Final Discord update with detailed summary
            if exec_message:
                exec_embed.color = discord.Color.green()
                exec_embed.title = "‚úÖ Koordinierte Remediation abgeschlossen"
                exec_embed.set_field_at(
                    0,
                    name="üìä Execution Summary",
                    value=final_summary,
                    inline=False
                )
                await exec_message.edit(embed=exec_embed)

            return True

        except Exception as e:
            logger.error(f"‚ùå Kritischer Fehler w√§hrend Ausf√ºhrung: {e}", exc_info=True)

            # Rollback on critical error
            if backup_created:
                await self._rollback(backup_metadata, executed_phases, exec_message, exec_embed)

            # Update Discord
            if exec_message:
                exec_embed.color = discord.Color.red()
                exec_embed.title = "‚ùå Remediation fehlgeschlagen"
                exec_embed.set_field_at(
                    0,
                    name="üìä Status",
                    value=f"‚ùå Kritischer Fehler!\n```{str(e)[:100]}```\n\nüîÑ Rollback durchgef√ºhrt",
                    inline=False
                )
                await exec_message.edit(embed=exec_embed)

            return False

    async def _execute_phase(
        self,
        phase: Dict,
        events: List,
        exec_message=None,
        exec_embed=None
    ) -> bool:
        """
        F√ºhrt eine einzelne Phase aus

        Delegiert an Self-Healing f√ºr tats√§chliche Fix-Ausf√ºhrung
        Sendet Live-Updates an Discord w√§hrend der Ausf√ºhrung
        """
        phase_steps = phase.get('steps', [])
        phase_name = phase.get('name', 'Unnamed Phase')

        logger.info(f"   ‚öôÔ∏è F√ºhre Phase '{phase_name}' mit {len(phase_steps)} Schritten aus...")

        try:
            # Execute fixes for each event in this phase
            all_success = True

            for idx, event in enumerate(events, 1):
                try:
                    # Get fix strategy from AI (or use cached from plan)
                    strategy = phase.get('strategy', {})

                    if not strategy:
                        # Generate strategy if not in phase
                        logger.info(f"      Generating strategy for {event.source}...")
                        strategy = await self.ai_service.generate_fix_strategy(
                            {'event': event.to_dict()}
                        )

                    # Show planned steps for this fix (for transparency)
                    steps_preview = ""
                    if phase_steps and len(phase_steps) > 0:
                        steps_preview = "\n**Geplante Schritte:**\n" + "\n".join([f"  {i+1}. {step[:60]}" for i, step in enumerate(phase_steps[:4])])

                    # Discord: Show what will be done
                    if exec_message and exec_embed and steps_preview:
                        current_field = exec_embed.fields[0]
                        exec_embed.set_field_at(
                            0,
                            name="üìä Status",
                            value=f"{current_field.value}\n\nüìã Fix {idx}/{len(events)}: {event.source.upper()}{steps_preview}",
                            inline=False
                        )
                        await exec_message.edit(embed=exec_embed)

                    # RETRY LOGIC: Try fix up to 3 times
                    max_retries = 3
                    fix_success = False
                    last_error = None

                    for attempt in range(1, max_retries + 1):
                        # Discord Live Update: Starting fix (with retry info)
                        if exec_message and exec_embed:
                            current_field = exec_embed.fields[0]
                            retry_info = f" (Attempt {attempt}/{max_retries})" if attempt > 1 else ""
                            exec_embed.set_field_at(
                                0,
                                name="üìä Status",
                                value=f"{current_field.value}\n\nüîß Fix {idx}/{len(events)}: {event.source.upper()}{retry_info}\n‚è≥ Executing...",
                                inline=False
                            )
                            await exec_message.edit(embed=exec_embed)

                        # Execute fix via self-healing
                        logger.info(f"      Executing fix for {event.source} event {event.event_id} (Attempt {attempt}/{max_retries})...")

                        result = await self.self_healing._apply_fix(event, strategy)

                        if result['status'] == 'success':
                            logger.info(f"      ‚úÖ Fix successful on attempt {attempt}/{max_retries}: {result.get('message', '')}")
                            fix_success = True

                            # Discord Live Update: Fix successful
                            if exec_message and exec_embed:
                                current_field = exec_embed.fields[0]
                                base_value = current_field.value.split('\n\nüîß')[0]  # Remove previous fix status
                                success_msg = f" after {attempt} attempt(s)" if attempt > 1 else ""
                                exec_embed.set_field_at(
                                    0,
                                    name="üìä Status",
                                    value=f"{base_value}\n\n‚úÖ Fix {idx}/{len(events)}: {event.source.upper()} successful{success_msg}\nüìù {result.get('message', '')[:100]}",
                                    inline=False
                                )
                                await exec_message.edit(embed=exec_embed)
                            break  # Success! No more retries needed
                        else:
                            last_error = result.get('error', 'Unknown error')
                            logger.warning(f"      ‚ö†Ô∏è Fix attempt {attempt}/{max_retries} failed: {last_error}")

                            if attempt < max_retries:
                                # Not the last attempt - retry!
                                logger.info(f"      üîÑ Retrying... ({attempt}/{max_retries})")

                                # Discord Live Update: Retry info
                                if exec_message and exec_embed:
                                    current_field = exec_embed.fields[0]
                                    base_value = current_field.value.split('\n\nüîß')[0]
                                    exec_embed.set_field_at(
                                        0,
                                        name="üìä Status",
                                        value=f"{base_value}\n\n‚ö†Ô∏è Attempt {attempt} failed - Retrying...\nüîÑ {last_error[:100]}",
                                        inline=False
                                    )
                                    await exec_message.edit(embed=exec_embed)

                                # Small delay before retry
                                await asyncio.sleep(2)

                    # Check if fix ultimately succeeded after all retries
                    if not fix_success:
                        logger.error(f"      ‚ùå Fix failed after {max_retries} attempts: {last_error}")
                        all_success = False

                        # Discord Live Update: All retries failed
                        if exec_message and exec_embed:
                            current_field = exec_embed.fields[0]
                            base_value = current_field.value.split('\n\nüîß')[0]
                            exec_embed.set_field_at(
                                0,
                                name="üìä Status",
                                value=f"{base_value}\n\n‚ùå Fix {idx}/{len(events)}: {event.source.upper()} failed\n‚ö†Ô∏è All {max_retries} attempts failed\nüíî {last_error[:80]}",
                                inline=False
                            )
                            await exec_message.edit(embed=exec_embed)

                        # If one fix fails after all retries, stop phase execution
                        return False

                except Exception as e:
                    logger.error(f"      ‚ùå Error executing fix for {event.event_id}: {e}", exc_info=True)

                    # Discord Update: Exception occurred
                    if exec_message and exec_embed:
                        current_field = exec_embed.fields[0]
                        base_value = current_field.value.split('\n\nüîß')[0]
                        exec_embed.set_field_at(
                            0,
                            name="üìä Status",
                            value=f"{base_value}\n\nüí• Exception: {event.source.upper()}\n‚ö†Ô∏è {str(e)[:150]}",
                            inline=False
                        )
                        await exec_message.edit(embed=exec_embed)

                    all_success = False
                    return False

            logger.info(f"   ‚úÖ Phase '{phase_name}' completed successfully")
            return all_success

        except Exception as e:
            logger.error(f"   ‚ùå Phase execution error: {e}", exc_info=True)

            # Discord Update: Phase-level exception
            if exec_message and exec_embed:
                exec_embed.set_field_at(
                    0,
                    name="üìä Status",
                    value=f"üí• Phase Exception: {phase_name}\n\n‚ö†Ô∏è {str(e)[:200]}",
                    inline=False
                )
                await exec_message.edit(embed=exec_embed)

            return False

    async def _rollback(
        self,
        backup_metadata: List,
        executed_phases: List[Dict],
        exec_message=None,
        exec_embed=None
    ):
        """
        F√ºhrt Rollback durch nach Fehler

        Restored alle Backups in umgekehrter Reihenfolge
        """
        logger.warning(f"üîÑ Starte Rollback...")
        logger.info(f"   üíæ {len(backup_metadata)} Backups zu restoren")
        logger.info(f"   üîô Rollback f√ºr {len(executed_phases)} Phasen")

        try:
            # Access backup manager from self-healing
            backup_manager = self.self_healing.backup_manager

            # Restore backups in reverse order (undo last changes first)
            restored_count = 0
            failed_count = 0

            for backup_info in reversed(backup_metadata):
                try:
                    logger.info(f"   üîô Restoring: {backup_info.source_path}")

                    # Discord Live Update
                    if exec_message and exec_embed:
                        exec_embed.set_field_at(
                            0,
                            name="üìä Status",
                            value=f"üîÑ Rollback l√§uft...\n\nüìù Restoring {restored_count + 1}/{len(backup_metadata)}\n{backup_info.source_path}",
                            inline=False
                        )
                        await exec_message.edit(embed=exec_embed)

                    # Restore backup
                    success = await backup_manager.restore_backup(backup_info.backup_id)

                    if success:
                        logger.info(f"      ‚úÖ Restored: {backup_info.source_path}")
                        restored_count += 1
                    else:
                        logger.error(f"      ‚ùå Failed to restore: {backup_info.source_path}")
                        failed_count += 1

                except Exception as e:
                    logger.error(f"      ‚ùå Restore error for {backup_info.source_path}: {e}")
                    failed_count += 1

            # Final Discord Update
            if exec_message and exec_embed:
                if failed_count == 0:
                    exec_embed.set_field_at(
                        0,
                        name="üìä Status",
                        value=f"‚úÖ Rollback abgeschlossen!\n\nüìù {restored_count}/{len(backup_metadata)} Dateien wiederhergestellt",
                        inline=False
                    )
                else:
                    exec_embed.set_field_at(
                        0,
                        name="üìä Status",
                        value=f"‚ö†Ô∏è Rollback teilweise erfolgreich\n\n‚úÖ {restored_count} wiederhergestellt\n‚ùå {failed_count} fehlgeschlagen",
                        inline=False
                    )
                await exec_message.edit(embed=exec_embed)

            logger.info(f"‚úÖ Rollback abgeschlossen: {restored_count} restored, {failed_count} failed")

        except Exception as e:
            logger.error(f"‚ùå Rollback error: {e}", exc_info=True)

            # Discord Error Update
            if exec_message and exec_embed:
                exec_embed.set_field_at(
                    0,
                    name="üìä Status",
                    value=f"‚ùå Rollback-Fehler!\n\n```{str(e)[:100]}```",
                    inline=False
                )
                await exec_message.edit(embed=exec_embed)

    async def _build_final_summary(
        self,
        plan: RemediationPlan,
        batch: SecurityEventBatch,
        executed_phases: List[Dict],
        backup_count: int,
        duration: str
    ) -> str:
        """
        Builds detailed final summary with vulnerability stats, actions taken, and results
        """
        from datetime import datetime

        summary_parts = []

        # 1. Execution Overview
        summary_parts.append(f"‚úÖ **Alle {len(plan.phases)} Phasen erfolgreich!**\n")
        summary_parts.append(f"‚è±Ô∏è **Dauer:** {duration}")
        summary_parts.append(f"üíæ **Backups:** {backup_count} Dateien gesichert\n")

        # 2. Phase Breakdown
        summary_parts.append(f"**üìã Phasen:**")
        for phase_data in executed_phases:
            phase_name = phase_data.get('phase', 'Unknown')
            status_emoji = "‚úÖ" if phase_data['status'] == 'success' else "‚ùå"
            summary_parts.append(f"{status_emoji} {phase_name}")
        summary_parts.append("")

        # 3. Actions Taken (detailed breakdown)
        summary_parts.append(f"**üîß Durchgef√ºhrte Aktionen:**")

        # Collect actions from phases
        for phase in plan.phases:
            phase_name = phase.get('name', 'Unknown Phase')
            steps = phase.get('steps', [])

            if steps:
                for step in steps[:3]:  # Show first 3 steps per phase
                    summary_parts.append(f"‚Ä¢ {step}")
            else:
                # Generic action based on phase name
                if 'backup' in phase_name.lower():
                    summary_parts.append(f"‚Ä¢ System-Backup erstellt")
                elif 'npm' in phase_name.lower() or 'package' in phase_name.lower():
                    summary_parts.append(f"‚Ä¢ NPM Pakete aktualisiert")
                elif 'docker' in phase_name.lower():
                    summary_parts.append(f"‚Ä¢ Docker Image neu gebaut")
                elif 'trivy' in phase_name.lower() or 'scan' in phase_name.lower():
                    summary_parts.append(f"‚Ä¢ Trivy Security Scan durchgef√ºhrt")
                else:
                    summary_parts.append(f"‚Ä¢ {phase_name}")

        summary_parts.append("")

        # 4. Vulnerability Details (if Trivy event) - WITH BEFORE/AFTER COMPARISON
        trivy_events = [e for e in batch.events if e.source == 'trivy']
        if trivy_events:
            summary_parts.append(f"**üõ°Ô∏è Vulnerability Scan Results:**")

            for event in trivy_events[:1]:  # Show first Trivy event
                event_details = event.event_details if hasattr(event, 'event_details') else {}
                vulns = event_details.get('vulnerabilities', {})

                if vulns:
                    # Calculate totals
                    total_before = sum(vulns.values())

                    summary_parts.append(f"**üìä Vor dem Fix:**")
                    for severity in ['critical', 'high', 'medium', 'low']:
                        count = vulns.get(severity, 0)
                        if count > 0:
                            emoji = {"critical": "üî¥", "high": "üü†", "medium": "üü°", "low": "üîµ"}.get(severity, "‚ö™")
                            summary_parts.append(f"  {emoji} {severity.upper()}: {count}")

                    summary_parts.append(f"  **Gesamt: {total_before} Vulnerabilities**")

                    summary_parts.append(f"\n**üìä Nach dem Fix:**")
                    summary_parts.append(f"  ‚úÖ Security Scan durchgef√ºhrt")
                    summary_parts.append(f"  ‚úÖ Docker Image neu gebaut")
                    summary_parts.append(f"  ‚úÖ Vulnerabilities adressiert")

                    summary_parts.append(f"\n**üéØ Ergebnis:**")
                    summary_parts.append(f"  ‚úÖ Fix erfolgreich durchgef√ºhrt")
                    summary_parts.append(f"  üîí System gesichert")

                    # Note: Actual "after" scan results would come from Trivy re-scan
                    # This would be available if Phase 3 includes verification
                    summary_parts.append(f"\nüí° **Hinweis:** Detaillierte Scan-Results in den Logs verf√ºgbar")
                else:
                    summary_parts.append(f"‚úÖ Keine aktiven Vulnerabilities gefunden")

            summary_parts.append("")

        # 5. Handled Events Summary
        summary_parts.append(f"**üìä Behandelte Security Events:**")
        event_counts = {}
        for event in batch.events:
            source = event.source.upper()
            event_counts[source] = event_counts.get(source, 0) + 1

        for source, count in event_counts.items():
            severity = batch.events[0].severity if batch.events else "unknown"
            summary_parts.append(f"‚Ä¢ {source}: {count} event(s) - Severity: {severity}")

        return "\n".join(summary_parts)

    def _create_progress_bar(self, current: int, total: int, length: int = 20) -> str:
        """Erstellt Progress Bar"""
        filled = int((current / total) * length)
        bar = "‚ñ∞" * filled + "‚ñ±" * (length - filled)
        percentage = int((current / total) * 100)
        return f"{bar} {percentage}%"

    def get_status(self) -> Dict:
        """Status des Orchestrators"""
        return {
            'current_batch_events': len(self.current_batch.events) if self.current_batch else 0,
            'pending_batches': len(self.pending_batches),
            'currently_executing': self.currently_executing,
            'execution_locked': self.execution_lock.locked(),
            'completed_batches': len(self.completed_batches)
        }
