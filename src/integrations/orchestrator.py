"""
Security Remediation Orchestrator

Koordiniert ALLE Security-Events in einem Master-Prozess um Race Conditions
und Konflikte zwischen parallelen Fixes zu vermeiden.

Workflow:
1. Sammelt alle Events in einem Zeitfenster (Batch)
2. KI erstellt einen koordinierten Gesamt-Plan
3. User Approval (einmal fÃ¼r den gesamten Plan)
4. Sequentielle AusfÃ¼hrung mit System-Locks
5. Comprehensive Testing und Rollback bei Problemen
"""

import asyncio
import json
import logging
import os
import time
from typing import Dict, List, Optional, Set
from dataclasses import dataclass, field
from datetime import datetime, timedelta

logger = logging.getLogger('shadowops')


@dataclass
class SecurityEventBatch:
    """Batch von Security-Events die zusammen behandelt werden"""
    events: List = field(default_factory=list)
    batch_id: str = ""
    created_at: float = 0.0
    status: str = "collecting"  # collecting, analyzing, awaiting_approval, executing, completed, failed
    status_message_id: Optional[int] = None  # Discord Message ID fÃ¼r Live-Updates
    status_channel_id: Optional[int] = None  # Discord Channel ID fÃ¼r Live-Updates

    def __post_init__(self):
        if not self.batch_id:
            self.batch_id = f"batch_{int(time.time())}"
        if not self.created_at:
            self.created_at = time.time()

    @property
    def severity_priority(self) -> int:
        """HÃ¶chste Severity im Batch (fÃ¼r Priorisierung)"""
        severity_map = {'CRITICAL': 4, 'HIGH': 3, 'MEDIUM': 2, 'LOW': 1, 'UNKNOWN': 0}
        return max([severity_map.get(e.severity, 0) for e in self.events], default=0)

    @property
    def sources(self) -> Set[str]:
        """Alle Event-Quellen im Batch"""
        return {e.source for e in self.events}

    def add_event(self, event):
        """FÃ¼gt Event zum Batch hinzu"""
        self.events.append(event)


@dataclass
class RemediationPlan:
    """Koordinierter Gesamt-Plan fÃ¼r alle Fixes"""
    batch_id: str
    description: str
    phases: List[Dict] = field(default_factory=list)
    confidence: float = 0.0
    estimated_duration_minutes: int = 0
    requires_restart: bool = False
    rollback_plan: str = ""
    ai_model: str = ""
    created_at: float = field(default_factory=time.time)


class RemediationOrchestrator:
    """
    Master Coordinator fÃ¼r alle Security Remediations

    Verhindert Race Conditions durch:
    - Event Batching (sammelt Events Ã¼ber 10s)
    - Koordinierte KI-Analyse (ALLE Events zusammen)
    - Single Approval Flow
    - Sequentielle AusfÃ¼hrung mit System-Locks
    """

    def __init__(self, ai_service, self_healing_coordinator, approval_manager, bot=None):
        self.ai_service = ai_service
        self.self_healing = self_healing_coordinator
        self.approval_manager = approval_manager
        self.bot = bot  # Discord Bot fÃ¼r Approval Messages

        # Event Batching
        self.collection_window_seconds = 10  # Sammelt Events Ã¼ber 10 Sekunden
        self.current_batch: Optional[SecurityEventBatch] = None
        self.batch_lock = asyncio.Lock()
        self.collection_task: Optional[asyncio.Task] = None

        # Execution Lock (nur 1 Remediation zur Zeit!)
        self.execution_lock = asyncio.Lock()
        self.currently_executing: Optional[str] = None

        # Batch Queue
        self.pending_batches: List[SecurityEventBatch] = []
        self.completed_batches: List[SecurityEventBatch] = []

        # NEW: Event History for Learning
        self.event_history: Dict[str, List[Dict]] = {}  # {event_signature: [attempts]}
        self.history_file = 'logs/event_history.json'
        self._load_event_history()

        logger.info("ğŸ¯ Remediation Orchestrator initialisiert")
        logger.info(f"   ğŸ“Š Batching Window: {self.collection_window_seconds}s")
        logger.info("   ğŸ”’ Sequential Execution Mode: ON")

    def _load_event_history(self):
        """Load event history from disk for learning"""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r') as f:
                    self.event_history = json.load(f)
                logger.info(f"ğŸ“š Loaded {len(self.event_history)} event type histories")

                # Count total attempts
                total_attempts = sum(len(attempts) for attempts in self.event_history.values())
                if total_attempts > 0:
                    logger.info(f"   ğŸ“– Total historical attempts: {total_attempts}")
            else:
                logger.info("ğŸ“š No event history found, starting fresh")
        except Exception as e:
            logger.error(f"âŒ Error loading event history: {e}")
            self.event_history = {}

    def _save_event_history(self):
        """Save event history to disk for persistence"""
        try:
            os.makedirs(os.path.dirname(self.history_file), exist_ok=True)
            with open(self.history_file, 'w') as f:
                json.dump(self.event_history, f, indent=2, default=str)
            logger.debug("ğŸ’¾ Event history saved")
        except Exception as e:
            logger.error(f"âŒ Error saving event history: {e}")

    def _get_status_channel(self):
        """Holt den Status-Channel fÃ¼r Live-Updates"""
        if not self.bot:
            return None
        # Verwende den Approval-Channel fÃ¼r Live-Updates
        try:
            approval_channel_id = 1438503737315299351  # auto-remediation-approvals
            channel = self.bot.get_channel(approval_channel_id)
            return channel
        except Exception as e:
            logger.error(f"Fehler beim Holen des Status-Channels: {e}")
        return None

    async def _send_batch_status(self, batch: SecurityEventBatch, status_text: str, color: int = 0xFFAA00):
        """Sendet oder updated Status-Message fÃ¼r einen Batch"""
        import discord

        channel = self._get_status_channel()
        if not channel:
            logger.warning("âš ï¸ Status-Channel nicht verfÃ¼gbar - Ã¼berspringe Discord-Update")
            return

        try:
            embed = discord.Embed(
                title="ğŸ”„ Koordinierte Remediation lÃ¤uft",
                description=status_text,
                color=color,
                timestamp=datetime.now()
            )
            embed.set_footer(text=f"Batch ID: {batch.batch_id}")

            if batch.status_message_id:
                # Update existing message
                try:
                    message = await channel.fetch_message(batch.status_message_id)
                    await message.edit(embed=embed)
                    logger.debug(f"ğŸ“ Discord-Status updated (Message ID: {batch.status_message_id})")
                except:
                    # Message not found, send new one
                    message = await channel.send(embed=embed)
                    batch.status_message_id = message.id
                    batch.status_channel_id = channel.id
                    logger.info(f"ğŸ“¤ Neue Discord-Status-Message gesendet (ID: {message.id})")
            else:
                # Send new message
                message = await channel.send(embed=embed)
                batch.status_message_id = message.id
                batch.status_channel_id = channel.id
                logger.info(f"ğŸ“¤ Neue Discord-Status-Message gesendet (ID: {message.id})")

        except Exception as e:
            logger.error(f"Fehler beim Senden der Status-Message: {e}")

    async def submit_event(self, event):
        """
        Event zum Orchestrator hinzufÃ¼gen

        Startet automatisch Batch-Collection wenn nÃ¶tig
        """
        async with self.batch_lock:
            # Erstelle neuen Batch wenn nÃ¶tig
            if self.current_batch is None:
                self.current_batch = SecurityEventBatch()
                logger.info(f"ğŸ“¦ Neuer Event-Batch gestartet: {self.current_batch.batch_id}")

                # Starte Collection Timer
                self.collection_task = asyncio.create_task(self._close_batch_after_timeout())

                # Sende initiale Discord-Message
                status_text = f"ğŸ“¦ **Neuer Remediation-Batch gestartet**\n\nâ±ï¸ Sammle Events fÃ¼r {self.collection_window_seconds} Sekunden..."
                await self._send_batch_status(self.current_batch, status_text, 0x3498DB)

            # FÃ¼ge Event zum aktuellen Batch hinzu
            self.current_batch.add_event(event)
            logger.info(f"   â• Event hinzugefÃ¼gt: {event.source} ({event.severity})")
            logger.info(f"   ğŸ“Š Batch Status: {len(self.current_batch.events)} Events")

            # Update Discord-Message mit neuem Event
            event_list = "\n".join([f"â€¢ **{e.source.upper()}**: {e.severity}" for e in self.current_batch.events])
            elapsed = int(time.time() - self.current_batch.created_at)
            remaining = max(0, self.collection_window_seconds - elapsed)
            status_text = f"ğŸ“¦ **Sammle Security-Events**\n\n{event_list}\n\nâ±ï¸ Verbleibend: **{remaining}s** | Events: **{len(self.current_batch.events)}**"
            await self._send_batch_status(self.current_batch, status_text, 0x3498DB)

    async def _close_batch_after_timeout(self):
        """SchlieÃŸt Batch nach Collection Window mit Live-Countdown-Updates"""
        update_interval = 2  # Update Discord alle 2 Sekunden
        elapsed = 0

        batch = self.current_batch  # Referenz speichern

        while elapsed < self.collection_window_seconds:
            await asyncio.sleep(update_interval)
            elapsed += update_interval

            # Update Discord mit Countdown
            async with self.batch_lock:
                if self.current_batch == batch and len(batch.events) > 0:
                    remaining = max(0, self.collection_window_seconds - elapsed)
                    event_list = "\n".join([f"â€¢ **{e.source.upper()}**: {e.severity}" for e in batch.events])

                    # Progress bar
                    progress = min(100, int((elapsed / self.collection_window_seconds) * 100))
                    bar_length = 20
                    filled = int((progress / 100) * bar_length)
                    bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)

                    status_text = f"ğŸ“¦ **Sammle Security-Events**\n\n{event_list}\n\nâ±ï¸ **{remaining}s** verbleibend | Events: **{len(batch.events)}**\n\n{bar} {progress}%"
                    await self._send_batch_status(batch, status_text, 0x3498DB)

        async with self.batch_lock:
            if self.current_batch and len(self.current_batch.events) > 0:
                logger.info(f"â° Batch-Collection abgelaufen ({self.collection_window_seconds}s)")
                logger.info(f"   ğŸ“¦ Batch {self.current_batch.batch_id}: {len(self.current_batch.events)} Events")
                logger.info(f"   ğŸ” Quellen: {', '.join(self.current_batch.sources)}")

                # Final Discord Update
                event_list = "\n".join([f"â€¢ **{e.source.upper()}**: {e.severity}" for e in self.current_batch.events])
                status_text = f"âœ… **Batch geschlossen**\n\n{event_list}\n\nğŸ“Š Total: **{len(self.current_batch.events)} Events**\nğŸ” Quellen: {', '.join(self.current_batch.sources)}\n\nğŸ§  Starte KI-Analyse..."
                await self._send_batch_status(self.current_batch, status_text, 0xF39C12)

                # Batch zur Verarbeitung verschieben
                self.current_batch.status = "analyzing"
                self.pending_batches.append(self.current_batch)
                self.current_batch = None

                # Starte Verarbeitung
                asyncio.create_task(self._process_next_batch())

    async def _process_next_batch(self):
        """Verarbeitet nÃ¤chsten Batch (mit Execution Lock!)"""

        # Warte auf Execution Lock (nur 1 Remediation gleichzeitig!)
        if self.execution_lock.locked():
            logger.info("â³ Execution Lock aktiv - warte auf Abschluss der laufenden Remediation...")
            return

        async with self.execution_lock:
            if not self.pending_batches:
                return

            # Hole Batch mit hÃ¶chster PrioritÃ¤t
            batch = max(self.pending_batches, key=lambda b: b.severity_priority)
            self.pending_batches.remove(batch)
            self.currently_executing = batch.batch_id

            logger.info(f"ğŸš€ Starte koordinierte Remediation fÃ¼r Batch {batch.batch_id}")
            logger.info(f"   ğŸ“Š {len(batch.events)} Events aus {len(batch.sources)} Quellen")

            try:
                # Phase 1: KI erstellt koordinierten Gesamt-Plan
                logger.info("ğŸ§  Phase 1: KI-Analyse aller Events...")
                plan = await self._create_coordinated_plan(batch)

                if not plan:
                    logger.error(f"âŒ KI konnte keinen Plan erstellen fÃ¼r Batch {batch.batch_id}")
                    batch.status = "failed"
                    self.completed_batches.append(batch)
                    return

                logger.info(f"âœ… Koordinierter Plan erstellt:")
                logger.info(f"   ğŸ“ {len(plan.phases)} Phasen")
                logger.info(f"   â±ï¸  GeschÃ¤tzte Dauer: {plan.estimated_duration_minutes} Minuten")
                logger.info(f"   ğŸ¯ Confidence: {plan.confidence:.0%}")

                # Phase 2: User Approval (einmal fÃ¼r ALLES)
                logger.info("ğŸ‘¤ Phase 2: Warte auf User-Approval...")
                approved = await self._request_approval(batch, plan)

                if not approved:
                    logger.warning(f"âŒ User hat Batch {batch.batch_id} abgelehnt")
                    batch.status = "rejected"
                    self.completed_batches.append(batch)
                    return

                # Phase 3: Sequentielle AusfÃ¼hrung
                logger.info("âš™ï¸ Phase 3: Sequentielle AusfÃ¼hrung...")
                batch.status = "executing"
                success = await self._execute_plan(batch, plan)

                if success:
                    logger.info(f"âœ… Batch {batch.batch_id} erfolgreich abgeschlossen!")
                    batch.status = "completed"
                else:
                    logger.error(f"âŒ Batch {batch.batch_id} fehlgeschlagen")
                    batch.status = "failed"

                self.completed_batches.append(batch)

            except Exception as e:
                logger.error(f"âŒ Orchestrator Error fÃ¼r Batch {batch.batch_id}: {e}", exc_info=True)
                batch.status = "failed"
                self.completed_batches.append(batch)

            finally:
                self.currently_executing = None

                # Verarbeite nÃ¤chsten Batch falls vorhanden
                if self.pending_batches:
                    asyncio.create_task(self._process_next_batch())

    async def _create_coordinated_plan(self, batch: SecurityEventBatch) -> Optional[RemediationPlan]:
        """
        KI erstellt koordinierten Gesamt-Plan fÃ¼r ALLE Events zusammen

        Wichtig: Die KI analysiert alle Events zusammen und erkennt:
        - AbhÃ¤ngigkeiten zwischen Fixes
        - Optimale Reihenfolge
        - Gemeinsame Schritte (z.B. ein Backup fÃ¼r alle)
        """

        # Sende initiale Discord-Message: KI-Analyse startet
        status_text = "ğŸ§  **KI-Analyse startet**\n\nLlama3.1 analysiert alle Events und erstellt koordinierten Plan...\n\nâ³ Dies kann 2-3 Minuten dauern"
        await self._send_batch_status(batch, status_text, 0xF39C12)  # Orange

        # Build comprehensive context with ALL events
        context = {
            'batch_id': batch.batch_id,
            'events': [e.to_dict() for e in batch.events],
            'event_count': len(batch.events),
            'sources': list(batch.sources),
            'highest_severity': max([e.severity for e in batch.events], key=lambda s: {'CRITICAL': 4, 'HIGH': 3, 'MEDIUM': 2, 'LOW': 1}.get(s, 0)),
            'is_coordinated_planning': True  # Flag for JSON parser
        }

        # Create streaming state for live Discord updates
        streaming_state = {
            'token_count': 0,
            'last_snippet': '',
            'batch': batch,
            'start_time': time.time()
        }
        context['streaming_state'] = streaming_state

        # Special prompt for coordinated planning
        prompt = self._build_coordinated_planning_prompt(context)

        # Use AI to create coordinated plan
        logger.info("ğŸ§  Rufe KI fÃ¼r koordinierte Planung auf...")

        # Start background task for live Discord updates wÃ¤hrend Streaming
        update_task = asyncio.create_task(self._stream_ai_progress_to_discord(streaming_state))

        try:
            # Use generate_coordinated_plan with coordinated planning context
            result = await self.ai_service.generate_coordinated_plan(prompt, context)

            # Stop streaming updates
            streaming_state['done'] = True
            await update_task  # Wait for final update

            if not result:
                logger.error("âŒ KI konnte keinen koordinierten Plan erstellen")
                status_text = "âŒ **KI-Analyse fehlgeschlagen**\n\nKonnte keinen koordinierten Plan erstellen"
                await self._send_batch_status(batch, status_text, 0xE74C3C)  # Red
                return None

            # Parse AI response into RemediationPlan
            plan = RemediationPlan(
                batch_id=batch.batch_id,
                description=result.get('description', 'Koordinierte Remediation'),
                phases=result.get('phases', []),
                confidence=result.get('confidence', 0.0),
                estimated_duration_minutes=result.get('estimated_duration_minutes', 30),
                requires_restart=result.get('requires_restart', False),
                rollback_plan=result.get('rollback_plan', 'Automatisches Rollback via Backups'),
                ai_model=result.get('ai_model', 'unknown')
            )

            # Sende finale Discord-Message: Plan erstellt
            phase_names = "\n".join([f"â€¢ **Phase {i+1}**: {p['name']}" for i, p in enumerate(plan.phases)])
            status_text = f"âœ… **Plan erstellt**\n\n{phase_names}\n\nâ±ï¸ GeschÃ¤tzte Dauer: **{plan.estimated_duration_minutes}min**\nğŸ¯ Confidence: **{plan.confidence:.0%}**"
            await self._send_batch_status(batch, status_text, 0x2ECC71)  # Green

            logger.info(f"âœ… Koordinierter Plan erstellt: {len(plan.phases)} Phasen, {plan.confidence:.0%} Confidence")
            return plan

        except Exception as e:
            # Stop streaming updates on error
            streaming_state['done'] = True
            try:
                await update_task
            except:
                pass

            logger.error(f"âŒ Fehler bei koordinierter Planung: {e}", exc_info=True)
            status_text = f"âŒ **KI-Analyse fehlgeschlagen**\n\nFehler: {str(e)}"
            await self._send_batch_status(batch, status_text, 0xE74C3C)  # Red
            return None

    async def _stream_ai_progress_to_discord(self, streaming_state: Dict):
        """
        Monitored streaming_state und sendet Live-Updates wÃ¤hrend KI-Analyse
        """
        batch = streaming_state['batch']
        update_interval = 5  # Update Discord alle 5 Sekunden
        expected_tokens = 400  # Llama3.1 generiert ~400 tokens fÃ¼r einen Plan

        last_token_count = 0

        while not streaming_state.get('done', False):
            await asyncio.sleep(update_interval)

            token_count = streaming_state.get('token_count', 0)
            last_snippet = streaming_state.get('last_snippet', '')
            elapsed = int(time.time() - streaming_state['start_time'])

            # Nur updaten wenn neue Tokens generiert wurden
            if token_count > last_token_count:
                last_token_count = token_count

                # Progress bar basierend auf Token-Count
                progress = min(100, int((token_count / expected_tokens) * 100))
                bar_length = 20
                filled = int((progress / 100) * bar_length)
                bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)

                # Format snippet fÃ¼r Discord (max 100 chars)
                snippet_preview = last_snippet[:100] + "..." if len(last_snippet) > 100 else last_snippet

                # GeschÃ¤tzte Restzeit (basierend auf bisheriger Speed)
                if token_count > 0 and elapsed > 0:
                    tokens_per_sec = token_count / elapsed
                    remaining_tokens = max(0, expected_tokens - token_count)
                    eta_seconds = int(remaining_tokens / tokens_per_sec) if tokens_per_sec > 0 else 0
                    eta_text = f"â±ï¸ ETA: ~{eta_seconds}s"
                else:
                    eta_text = "â±ï¸ ETA: Berechne..."

                # Phase detection aus snippet
                phase_info = ""
                if "Phase 1" in last_snippet or "Backup" in last_snippet:
                    phase_info = "ğŸ” Analysiere: **Phase 1 (Backup)**"
                elif "Phase 2" in last_snippet or "Docker" in last_snippet or "Update" in last_snippet:
                    phase_info = "ğŸ” Analysiere: **Phase 2 (Updates)**"
                elif "Phase 3" in last_snippet or "trivy" in last_snippet.lower() or "Remediation" in last_snippet:
                    phase_info = "ğŸ” Analysiere: **Phase 3 (Remediation)**"
                elif token_count > 50:
                    phase_info = "ğŸ” Analysiere: **Sicherheitsplan**"

                status_text = f"ğŸ§  **KI-Analyse lÃ¤uft**\n\n{phase_info}\n\nğŸ“Š Tokens: **{token_count}** / ~{expected_tokens}\nâš¡ Zeit: **{elapsed}s** | {eta_text}\n\n{bar} {progress}%"

                # FÃ¼ge snippet hinzu falls vorhanden
                if snippet_preview:
                    status_text += f"\n\nğŸ’¬ *\"{snippet_preview}\"*"

                await self._send_batch_status(batch, status_text, 0xF39C12)  # Orange

        # Finale Message falls noch nicht von _create_coordinated_plan() gesendet
        # (kann passieren wenn done=True gesetzt wird bevor letzte Update)

    def _build_coordinated_planning_prompt(self, context: Dict) -> str:
        """Baut Prompt fÃ¼r koordinierte Planung mit Infrastructure Context"""

        prompt_parts = []

        # ADD: Context Manager Integration for Infrastructure Knowledge
        if self.ai_service and hasattr(self.ai_service, 'context_manager') and self.ai_service.context_manager:
            prompt_parts.append("# INFRASTRUCTURE & PROJECT KNOWLEDGE BASE")
            prompt_parts.append("Du hast Zugriff auf detaillierte Informationen Ã¼ber die Server-Infrastruktur und laufende Projekte.")
            prompt_parts.append("Nutze diesen Kontext fÃ¼r informierte, sichere Entscheidungen.\n")

            # Get relevant context for all events in batch
            for event in context['events']:
                relevant_context = self.ai_service.context_manager.get_relevant_context(
                    event['source'],
                    event.get('event_type', 'unknown')
                )
                if relevant_context:
                    prompt_parts.append(relevant_context)
                    break  # Only add context once (same for all events in batch)

            prompt_parts.append("\n" + "="*80 + "\n")

        # Main coordination prompt
        prompt_parts.append(f"""# Koordinierte Security Remediation

Du bist ein Security-Engineer der einen KOORDINIERTEN Gesamt-Plan erstellt.

## Wichtig:
- Analysiere ALLE {context['event_count']} Events ZUSAMMEN
- Nutze den INFRASTRUCTURE & PROJECT KNOWLEDGE BASE Kontext oben
- Erkenne AbhÃ¤ngigkeiten zwischen Projekten und Services
- Erstelle EINE sequentielle AusfÃ¼hrungs-Pipeline
- Vermeide Race Conditions und Breaking Changes
- BerÃ¼cksichtige laufende Services (docker-compose.yml, Versionen)

## Events im Batch:
""")

        for i, event in enumerate(context['events'], 1):
            prompt_parts.append(f"\n### Event {i}: {event['source']} ({event['severity']})\n")
            prompt_parts.append(f"```\n{event.get('details', 'N/A')}\n```\n")

        prompt_parts.append("""

## Aufgabe:
Erstelle einen koordinierten Plan mit Phasen die NACHEINANDER ausgefÃ¼hrt werden.

**WICHTIG: Alle Texte MÃœSSEN auf DEUTSCH sein!**

Ausgabe als JSON:
{
  "description": "Kurze Beschreibung des Gesamt-Plans (DEUTSCH)",
  "confidence": 0.XX,
  "estimated_duration_minutes": XX,
  "requires_restart": true/false,
  "phases": [
    {
      "name": "Phase 1: Backup",
      "description": "System-Backup erstellen",
      "steps": ["Schritt 1", "Schritt 2"],
      "estimated_minutes": 5
    },
    {
      "name": "Phase 2: Docker Updates",
      "description": "CVEs in Docker Images beheben",
      "steps": ["Update packages", "Rebuild images", "Test"],
      "estimated_minutes": 15
    }
  ],
  "rollback_plan": "Beschreibung wie Rollback funktioniert (DEUTSCH)"
}
""")

        return "\n".join(prompt_parts)

    async def _request_approval(self, batch: SecurityEventBatch, plan: RemediationPlan) -> bool:
        """
        Fordert User-Approval fÃ¼r den gesamten koordinierten Plan an

        Zeigt ein schÃ¶nes Discord Embed mit:
        - Zusammenfassung aller Events
        - Alle Phasen des Plans
        - GeschÃ¤tzte Dauer
        - Risiko-Level
        - Approve/Reject Buttons
        """
        import discord

        logger.info(f"ğŸ‘¤ Fordere Approval an fÃ¼r Batch {batch.batch_id}")

        # Build Discord Embed
        embed = discord.Embed(
            title="ğŸ¯ Koordinierter Remediation-Plan",
            description=f"**{plan.description}**\n\nDieser Plan behandelt **{len(batch.events)} Security-Events** koordiniert und sequentiell.",
            color=discord.Color.gold(),
            timestamp=datetime.now()
        )

        # Events Summary
        sources_summary = {}
        for event in batch.events:
            source = event.source
            if source not in sources_summary:
                sources_summary[source] = {'count': 0, 'severity': event.severity}
            sources_summary[source]['count'] += 1

        events_text = "\n".join([
            f"**{source.upper()}:** {info['count']} Event(s) ({info['severity']})"
            for source, info in sources_summary.items()
        ])

        embed.add_field(
            name="ğŸ“¦ Events im Batch",
            value=events_text,
            inline=False
        )

        # Execution Plan (Phasen)
        phases_text = ""
        total_minutes = 0
        for i, phase in enumerate(plan.phases[:5], 1):  # Max 5 Phasen anzeigen
            name = phase.get('name', f'Phase {i}')
            desc = phase.get('description', 'N/A')
            minutes = phase.get('estimated_minutes', 5)
            total_minutes += minutes

            phases_text += f"**{i}. {name}** (~{minutes}min)\n{desc}\n\n"

        if len(plan.phases) > 5:
            phases_text += f"_...und {len(plan.phases) - 5} weitere Phasen_\n"

        embed.add_field(
            name="âš™ï¸ AusfÃ¼hrungs-Plan",
            value=phases_text or "Keine Phasen definiert",
            inline=False
        )

        # Metadata
        confidence_color = "ğŸŸ¢" if plan.confidence >= 0.8 else "ğŸŸ¡" if plan.confidence >= 0.6 else "ğŸ”´"

        embed.add_field(
            name="ğŸ“Š Plan-Details",
            value=f"**Confidence:** {confidence_color} {plan.confidence:.0%}\n"
                  f"**GeschÃ¤tzte Dauer:** â±ï¸ ~{total_minutes} Minuten\n"
                  f"**Neustart erforderlich:** {'âœ… Ja' if plan.requires_restart else 'âŒ Nein'}\n"
                  f"**KI-Modell:** {plan.ai_model}",
            inline=False
        )

        # Rollback Info
        if plan.rollback_plan:
            embed.add_field(
                name="ğŸ”„ Rollback-Strategie",
                value=plan.rollback_plan[:200] + ("..." if len(plan.rollback_plan) > 200 else ""),
                inline=False
            )

        embed.set_footer(text=f"Batch ID: {batch.batch_id} | Orchestrator v1.0")

        # Send to approval channel with buttons
        try:
            if not self.bot:
                logger.warning("âš ï¸ Kein Bot verfÃ¼gbar fÃ¼r Approval - Auto-Approve")
                return True

            # Get approval channel
            approval_channel_id = 1438503737315299351  # auto-remediation-approvals
            channel = self.bot.get_channel(approval_channel_id)

            if not channel:
                logger.error(f"âŒ Approval Channel {approval_channel_id} nicht gefunden")
                return False

            # Create approval buttons
            import discord

            class ApprovalView(discord.ui.View):
                def __init__(self, orchestrator, batch_id):
                    super().__init__(timeout=1800)  # 30 minutes
                    self.orchestrator = orchestrator
                    self.batch_id = batch_id
                    self.approved = None

                @discord.ui.button(label="âœ… Approve & Execute", style=discord.ButtonStyle.green, custom_id="approve")
                async def approve_button(self, interaction: discord.Interaction, button: discord.ui.Button):
                    await interaction.response.send_message(
                        f"âœ… **Plan approved!** Starte koordinierte Remediation...",
                        ephemeral=True
                    )
                    self.approved = True
                    self.stop()

                @discord.ui.button(label="âŒ Reject", style=discord.ButtonStyle.red, custom_id="reject")
                async def reject_button(self, interaction: discord.Interaction, button: discord.ui.Button):
                    await interaction.response.send_message(
                        f"âŒ **Plan abgelehnt.** Remediation wird nicht ausgefÃ¼hrt.",
                        ephemeral=True
                    )
                    self.approved = False
                    self.stop()

                @discord.ui.button(label="ğŸ“‹ Details anzeigen", style=discord.ButtonStyle.gray, custom_id="details")
                async def details_button(self, interaction: discord.Interaction, button: discord.ui.Button):
                    # Build detailed view
                    details_text = f"**Batch {self.batch_id} - Detaillierte Phasen:**\n\n"

                    # Get plan from orchestrator
                    # For now, just acknowledge
                    await interaction.response.send_message(
                        f"ğŸ“‹ Detaillierte Phasen-Informationen fÃ¼r Batch `{self.batch_id}`\n\n"
                        f"Siehe Embed oben fÃ¼r vollstÃ¤ndige Details.",
                        ephemeral=True
                    )

            # Create view instance
            view = ApprovalView(self, batch.batch_id)

            # Send message with embed and buttons
            approval_message = await channel.send(embed=embed, view=view)
            logger.info(f"ğŸ“¬ Approval-Request gesendet an Channel {channel.name}")

            # Wait for user interaction
            logger.info(f"â³ Warte auf User-Approval (Timeout: 30min)...")
            await view.wait()

            # Update message to show result
            if view.approved is True:
                # Update embed color to green
                embed.color = discord.Color.green()
                embed.title = "âœ… Plan Approved - Wird ausgefÃ¼hrt"
                await approval_message.edit(embed=embed, view=None)
                logger.info(f"âœ… Batch {batch.batch_id} wurde approved")
                return True

            elif view.approved is False:
                # Update embed color to red
                embed.color = discord.Color.red()
                embed.title = "âŒ Plan Rejected"
                await approval_message.edit(embed=embed, view=None)
                logger.warning(f"âŒ Batch {batch.batch_id} wurde rejected")
                return False

            else:
                # Timeout
                embed.color = discord.Color.dark_gray()
                embed.title = "â° Approval Timeout - Plan verworfen"
                await approval_message.edit(embed=embed, view=None)
                logger.warning(f"â° Batch {batch.batch_id} - Approval Timeout")
                return False

        except Exception as e:
            logger.error(f"âŒ Fehler bei Approval-Request: {e}", exc_info=True)
            return False

    async def _execute_plan(self, batch: SecurityEventBatch, plan: RemediationPlan) -> bool:
        """
        FÃ¼hrt Plan sequentiell Phase fÃ¼r Phase aus

        Workflow:
        1. Erstelle System-Backup
        2. FÃ¼hre jede Phase nacheinander aus
        3. Teste nach jeder Phase
        4. Bei Fehler: Rollback und Stop
        5. Sende Discord-Updates wÃ¤hrend AusfÃ¼hrung
        """
        import discord
        from datetime import datetime

        logger.info(f"âš™ï¸ Starte sequentielle AusfÃ¼hrung von {len(plan.phases)} Phasen")

        # Track execution start time for duration calculation
        self._execution_start_time = datetime.now()

        # Get execution channel for live updates
        execution_channel = None
        if self.bot:
            try:
                # Send to remediation-alerts channel for live updates
                channel_id = 1438503736220586164  # auto-remediation-alerts
                execution_channel = self.bot.get_channel(channel_id)
            except Exception as e:
                logger.warning(f"âš ï¸ Konnte Execution-Channel nicht laden: {e}")

        # Create execution status embed
        exec_embed = None
        exec_message = None

        if execution_channel:
            exec_embed = discord.Embed(
                title="âš™ï¸ Koordinierte Remediation lÃ¤uft",
                description=f"**Batch {batch.batch_id}**\n{plan.description}",
                color=discord.Color.blue(),
                timestamp=datetime.now()
            )
            exec_embed.add_field(
                name="ğŸ“Š Status",
                value="ğŸ”„ Starte AusfÃ¼hrung...",
                inline=False
            )
            exec_message = await execution_channel.send(embed=exec_embed)

        # Track execution results
        executed_phases = []
        backup_created = False
        backup_path = None

        try:
            # Phase 0: Create system backup
            logger.info("ğŸ’¾ Phase 0: Erstelle System-Backup...")
            if exec_message:
                exec_embed.set_field_at(
                    0,
                    name="ğŸ“Š Status",
                    value="ğŸ’¾ Phase 0/0: System-Backup wird erstellt...",
                    inline=False
                )
                await exec_message.edit(embed=exec_embed)

            # Create backup using BackupManager from self_healing
            backup_manager = self.self_healing.backup_manager
            backup_metadata = []

            # Collect files to backup based on events
            files_to_backup = set()
            for event in batch.events:
                if event.source == 'trivy':
                    # Backup Docker-related files
                    files_to_backup.add('/home/cmdshadow/shadowops-bot/package.json')
                    files_to_backup.add('/home/cmdshadow/shadowops-bot/Dockerfile')
                elif event.source in ['fail2ban', 'crowdsec']:
                    # Backup firewall configs
                    files_to_backup.add('/etc/fail2ban/jail.local')
                    files_to_backup.add('/etc/ufw/user.rules')
                elif event.source == 'aide':
                    # Backup will be handled by AIDE fixer
                    pass

            # Create backups
            for file_path in files_to_backup:
                if os.path.exists(file_path):
                    try:
                        backup = await backup_manager.create_backup(
                            file_path,
                            metadata={'batch_id': batch.batch_id}
                        )
                        backup_metadata.append(backup)
                        logger.info(f"   ğŸ’¾ Backed up: {file_path}")
                    except Exception as e:
                        logger.warning(f"   âš ï¸ Could not backup {file_path}: {e}")

            backup_created = len(backup_metadata) > 0
            backup_path = f"Batch {batch.batch_id} - {len(backup_metadata)} backups created"
            logger.info(f"âœ… Backup Phase abgeschlossen: {len(backup_metadata)} Dateien gesichert")

            # Execute each phase sequentially
            for phase_idx, phase in enumerate(plan.phases, 1):
                phase_name = phase.get('name', f'Phase {phase_idx}')
                phase_desc = phase.get('description', '')
                phase_steps = phase.get('steps', [])

                logger.info(f"ğŸ”§ Phase {phase_idx}/{len(plan.phases)}: {phase_name}")
                logger.info(f"   ğŸ“ {phase_desc}")
                logger.info(f"   ğŸ“‹ {len(phase_steps)} Schritte")

                # Update Discord
                if exec_message:
                    progress_bar = self._create_progress_bar(phase_idx, len(plan.phases))
                    exec_embed.set_field_at(
                        0,
                        name="ğŸ“Š Status",
                        value=f"ğŸ”§ Phase {phase_idx}/{len(plan.phases)}: {phase_name}\n{progress_bar}\n\n{phase_desc}",
                        inline=False
                    )
                    await exec_message.edit(embed=exec_embed)

                # Execute phase steps (pass Discord message for live updates)
                phase_success = await self._execute_phase(
                    phase,
                    batch.events,
                    exec_message=exec_message,
                    exec_embed=exec_embed
                )

                if phase_success:
                    logger.info(f"âœ… Phase {phase_idx} erfolgreich")
                    executed_phases.append({
                        'phase': phase_name,
                        'status': 'success',
                        'index': phase_idx
                    })
                else:
                    logger.error(f"âŒ Phase {phase_idx} fehlgeschlagen!")
                    executed_phases.append({
                        'phase': phase_name,
                        'status': 'failed',
                        'index': phase_idx
                    })

                    # Rollback on failure
                    if exec_message:
                        exec_embed.color = discord.Color.red()
                        exec_embed.set_field_at(
                            0,
                            name="ğŸ“Š Status",
                            value=f"âŒ Phase {phase_idx} fehlgeschlagen!\nğŸ”„ Starte Rollback...",
                            inline=False
                        )
                        await exec_message.edit(embed=exec_embed)

                    await self._rollback(backup_metadata, executed_phases, exec_message, exec_embed)
                    return False

            # All phases successful!
            logger.info(f"âœ… Alle {len(plan.phases)} Phasen erfolgreich ausgefÃ¼hrt")

            # Calculate execution duration
            if hasattr(self, '_execution_start_time'):
                duration = (datetime.now() - self._execution_start_time).total_seconds()
                duration_str = f"{int(duration // 60)}m {int(duration % 60)}s"
            else:
                duration_str = "Unknown"

            # Build detailed final summary
            final_summary = await self._build_final_summary(
                plan=plan,
                batch=batch,
                executed_phases=executed_phases,
                backup_count=len(backup_metadata),
                duration=duration_str
            )

            # Final Discord update with detailed summary
            if exec_message:
                exec_embed.color = discord.Color.green()
                exec_embed.title = "âœ… Koordinierte Remediation abgeschlossen"
                exec_embed.set_field_at(
                    0,
                    name="ğŸ“Š Execution Summary",
                    value=final_summary,
                    inline=False
                )
                await exec_message.edit(embed=exec_embed)

            return True

        except Exception as e:
            logger.error(f"âŒ Kritischer Fehler wÃ¤hrend AusfÃ¼hrung: {e}", exc_info=True)

            # Rollback on critical error
            if backup_created:
                await self._rollback(backup_metadata, executed_phases, exec_message, exec_embed)

            # Update Discord
            if exec_message:
                exec_embed.color = discord.Color.red()
                exec_embed.title = "âŒ Remediation fehlgeschlagen"
                exec_embed.set_field_at(
                    0,
                    name="ğŸ“Š Status",
                    value=f"âŒ Kritischer Fehler!\n```{str(e)[:100]}```\n\nğŸ”„ Rollback durchgefÃ¼hrt",
                    inline=False
                )
                await exec_message.edit(embed=exec_embed)

            return False

    async def _execute_phase(
        self,
        phase: Dict,
        events: List,
        exec_message=None,
        exec_embed=None
    ) -> bool:
        """
        FÃ¼hrt eine einzelne Phase aus

        Delegiert an Self-Healing fÃ¼r tatsÃ¤chliche Fix-AusfÃ¼hrung
        Sendet Live-Updates an Discord wÃ¤hrend der AusfÃ¼hrung
        """
        phase_steps = phase.get('steps', [])
        phase_name = phase.get('name', 'Unnamed Phase')

        logger.info(f"   âš™ï¸ FÃ¼hre Phase '{phase_name}' mit {len(phase_steps)} Schritten aus...")

        try:
            # Execute fixes for each event in this phase
            all_success = True

            for idx, event in enumerate(events, 1):
                try:
                    # Build learning context once per event
                    event_signature = f"{event.source}_{event.event_type}"
                    previous_attempts = self.event_history.get(event_signature, [])[-3:]
                    if previous_attempts:
                        logger.info(f"      ğŸ“š Found {len(previous_attempts)} previous attempt(s) for {event_signature}")

                    # Get fix strategy from AI (or use cached from plan)
                    strategy = phase.get('strategy', {})

                    if not strategy:
                        # Generate strategy if not in phase
                        logger.info(f"      Generating strategy for {event.source}...")

                        strategy = await self.ai_service.generate_fix_strategy({
                            'event': event.to_dict(),
                            'previous_attempts': previous_attempts
                        })

                    # Show planned steps for this fix (for transparency)
                    steps_preview = ""
                    if phase_steps and len(phase_steps) > 0:
                        steps_preview = "\n**Geplante Schritte:**\n" + "\n".join([f"  {i+1}. {step[:60]}" for i, step in enumerate(phase_steps[:4])])

                    # Discord: Show what will be done
                    if exec_message and exec_embed and steps_preview:
                        current_field = exec_embed.fields[0]
                        exec_embed.set_field_at(
                            0,
                            name="ğŸ“Š Status",
                            value=f"{current_field.value}\n\nğŸ“‹ Fix {idx}/{len(events)}: {event.source.upper()}{steps_preview}",
                            inline=False
                        )
                        await exec_message.edit(embed=exec_embed)

                    # RETRY LOGIC: Try fix up to 3 times
                    max_retries = 3
                    fix_success = False
                    last_error = None

                    for attempt in range(1, max_retries + 1):
                        # Discord Live Update: Starting fix (with retry info)
                        if exec_message and exec_embed:
                            current_field = exec_embed.fields[0]
                            retry_info = f" (Attempt {attempt}/{max_retries})" if attempt > 1 else ""
                            exec_embed.set_field_at(
                                0,
                                name="ğŸ“Š Status",
                                value=f"{current_field.value}\n\nğŸ”§ Fix {idx}/{len(events)}: {event.source.upper()}{retry_info}\nâ³ Executing...",
                                inline=False
                            )
                            await exec_message.edit(embed=exec_embed)

                        # Execute fix via self-healing
                        logger.info(f"      Executing fix for {event.source} event {event.event_id} (Attempt {attempt}/{max_retries})...")

                        result = await self.self_healing._apply_fix(event, strategy)

                        if result['status'] == 'success':
                            logger.info(f"      âœ… Fix successful on attempt {attempt}/{max_retries}: {result.get('message', '')}")
                            fix_success = True

                            # NEW: Record successful fix in history for learning
                            if event_signature not in self.event_history:
                                self.event_history[event_signature] = []

                            self.event_history[event_signature].append({
                                'timestamp': datetime.now().isoformat(),
                                'strategy': strategy,
                                'result': 'success',
                                'message': result.get('message'),
                                'details': result.get('details'),
                                'attempt': attempt,
                                'phase': phase_name
                            })

                            # Keep only last 10 attempts per event type
                            self.event_history[event_signature] = self.event_history[event_signature][-10:]
                            self._save_event_history()

                            # Discord Live Update: Fix successful
                            if exec_message and exec_embed:
                                current_field = exec_embed.fields[0]
                                base_value = current_field.value.split('\n\nğŸ”§')[0]  # Remove previous fix status
                                success_msg = f" after {attempt} attempt(s)" if attempt > 1 else ""
                                exec_embed.set_field_at(
                                    0,
                                    name="ğŸ“Š Status",
                                    value=f"{base_value}\n\nâœ… Fix {idx}/{len(events)}: {event.source.upper()} successful{success_msg}\nğŸ“ {result.get('message', '')[:100]}",
                                    inline=False
                                )
                                await exec_message.edit(embed=exec_embed)
                            break  # Success! No more retries needed
                        else:
                            last_error = result.get('error', 'Unknown error')
                            logger.warning(f"      âš ï¸ Fix attempt {attempt}/{max_retries} failed: {last_error}")

                            # NEW: Record failed attempt in history for learning
                            if event_signature not in self.event_history:
                                self.event_history[event_signature] = []

                            self.event_history[event_signature].append({
                                'timestamp': datetime.now().isoformat(),
                                'strategy': strategy,
                                'result': 'failed',
                                'error': last_error,
                                'attempt': attempt,
                                'phase': phase_name
                            })

                            self.event_history[event_signature] = self.event_history[event_signature][-10:]
                            self._save_event_history()

                            if attempt < max_retries:
                                # Not the last attempt - retry!
                                logger.info(f"      ğŸ”„ Retrying... ({attempt}/{max_retries})")

                                # Discord Live Update: Retry info
                                if exec_message and exec_embed:
                                    current_field = exec_embed.fields[0]
                                    base_value = current_field.value.split('\n\nğŸ”§')[0]
                                    exec_embed.set_field_at(
                                        0,
                                        name="ğŸ“Š Status",
                                        value=f"{base_value}\n\nâš ï¸ Attempt {attempt} failed - Retrying...\nğŸ”„ {last_error[:100]}",
                                        inline=False
                                    )
                                    await exec_message.edit(embed=exec_embed)

                                # Small delay before retry
                                await asyncio.sleep(2)

                    # Check if fix ultimately succeeded after all retries
                    if not fix_success:
                        logger.error(f"      âŒ Fix failed after {max_retries} attempts: {last_error}")
                        all_success = False

                        # Discord Live Update: All retries failed
                        if exec_message and exec_embed:
                            current_field = exec_embed.fields[0]
                            base_value = current_field.value.split('\n\nğŸ”§')[0]
                            exec_embed.set_field_at(
                                0,
                                name="ğŸ“Š Status",
                                value=f"{base_value}\n\nâŒ Fix {idx}/{len(events)}: {event.source.upper()} failed\nâš ï¸ All {max_retries} attempts failed\nğŸ’” {last_error[:80]}",
                                inline=False
                            )
                            await exec_message.edit(embed=exec_embed)

                        # If one fix fails after all retries, stop phase execution
                        return False

                except Exception as e:
                    logger.error(f"      âŒ Error executing fix for {event.event_id}: {e}", exc_info=True)

                    # Discord Update: Exception occurred
                    if exec_message and exec_embed:
                        current_field = exec_embed.fields[0]
                        base_value = current_field.value.split('\n\nğŸ”§')[0]
                        exec_embed.set_field_at(
                            0,
                            name="ğŸ“Š Status",
                            value=f"{base_value}\n\nğŸ’¥ Exception: {event.source.upper()}\nâš ï¸ {str(e)[:150]}",
                            inline=False
                        )
                        await exec_message.edit(embed=exec_embed)

                    all_success = False
                    return False

            logger.info(f"   âœ… Phase '{phase_name}' completed successfully")
            return all_success

        except Exception as e:
            logger.error(f"   âŒ Phase execution error: {e}", exc_info=True)

            # Discord Update: Phase-level exception
            if exec_message and exec_embed:
                exec_embed.set_field_at(
                    0,
                    name="ğŸ“Š Status",
                    value=f"ğŸ’¥ Phase Exception: {phase_name}\n\nâš ï¸ {str(e)[:200]}",
                    inline=False
                )
                await exec_message.edit(embed=exec_embed)

            return False

    async def _rollback(
        self,
        backup_metadata: List,
        executed_phases: List[Dict],
        exec_message=None,
        exec_embed=None
    ):
        """
        FÃ¼hrt Rollback durch nach Fehler

        Restored alle Backups in umgekehrter Reihenfolge
        """
        logger.warning(f"ğŸ”„ Starte Rollback...")
        logger.info(f"   ğŸ’¾ {len(backup_metadata)} Backups zu restoren")
        logger.info(f"   ğŸ”™ Rollback fÃ¼r {len(executed_phases)} Phasen")

        try:
            # Access backup manager from self-healing
            backup_manager = self.self_healing.backup_manager

            # Restore backups in reverse order (undo last changes first)
            restored_count = 0
            failed_count = 0

            for backup_info in reversed(backup_metadata):
                try:
                    logger.info(f"   ğŸ”™ Restoring: {backup_info.source_path}")

                    # Discord Live Update
                    if exec_message and exec_embed:
                        exec_embed.set_field_at(
                            0,
                            name="ğŸ“Š Status",
                            value=f"ğŸ”„ Rollback lÃ¤uft...\n\nğŸ“ Restoring {restored_count + 1}/{len(backup_metadata)}\n{backup_info.source_path}",
                            inline=False
                        )
                        await exec_message.edit(embed=exec_embed)

                    # Restore backup
                    success = await backup_manager.restore_backup(backup_info.backup_id)

                    if success:
                        logger.info(f"      âœ… Restored: {backup_info.source_path}")
                        restored_count += 1
                    else:
                        logger.error(f"      âŒ Failed to restore: {backup_info.source_path}")
                        failed_count += 1

                except Exception as e:
                    logger.error(f"      âŒ Restore error for {backup_info.source_path}: {e}")
                    failed_count += 1

            # Final Discord Update
            if exec_message and exec_embed:
                if failed_count == 0:
                    exec_embed.set_field_at(
                        0,
                        name="ğŸ“Š Status",
                        value=f"âœ… Rollback abgeschlossen!\n\nğŸ“ {restored_count}/{len(backup_metadata)} Dateien wiederhergestellt",
                        inline=False
                    )
                else:
                    exec_embed.set_field_at(
                        0,
                        name="ğŸ“Š Status",
                        value=f"âš ï¸ Rollback teilweise erfolgreich\n\nâœ… {restored_count} wiederhergestellt\nâŒ {failed_count} fehlgeschlagen",
                        inline=False
                    )
                await exec_message.edit(embed=exec_embed)

            logger.info(f"âœ… Rollback abgeschlossen: {restored_count} restored, {failed_count} failed")

        except Exception as e:
            logger.error(f"âŒ Rollback error: {e}", exc_info=True)

            # Discord Error Update
            if exec_message and exec_embed:
                exec_embed.set_field_at(
                    0,
                    name="ğŸ“Š Status",
                    value=f"âŒ Rollback-Fehler!\n\n```{str(e)[:100]}```",
                    inline=False
                )
                await exec_message.edit(embed=exec_embed)

    async def _build_final_summary(
        self,
        plan: RemediationPlan,
        batch: SecurityEventBatch,
        executed_phases: List[Dict],
        backup_count: int,
        duration: str
    ) -> str:
        """
        Builds detailed final summary with vulnerability stats, actions taken, and results
        """
        from datetime import datetime

        summary_parts = []

        # 1. Execution Overview
        summary_parts.append(f"âœ… **Alle {len(plan.phases)} Phasen erfolgreich!**\n")
        summary_parts.append(f"â±ï¸ **Dauer:** {duration}")
        summary_parts.append(f"ğŸ’¾ **Backups:** {backup_count} Dateien gesichert\n")

        # 2. Phase Breakdown
        summary_parts.append(f"**ğŸ“‹ Phasen:**")
        for phase_data in executed_phases:
            phase_name = phase_data.get('phase', 'Unknown')
            status_emoji = "âœ…" if phase_data['status'] == 'success' else "âŒ"
            summary_parts.append(f"{status_emoji} {phase_name}")
        summary_parts.append("")

        # 3. Actions Taken (detailed breakdown)
        summary_parts.append(f"**ğŸ”§ DurchgefÃ¼hrte Aktionen:**")

        # Collect actions from phases
        for phase in plan.phases:
            phase_name = phase.get('name', 'Unknown Phase')
            steps = phase.get('steps', [])

            if steps:
                for step in steps[:3]:  # Show first 3 steps per phase
                    summary_parts.append(f"â€¢ {step}")
            else:
                # Generic action based on phase name
                if 'backup' in phase_name.lower():
                    summary_parts.append(f"â€¢ System-Backup erstellt")
                elif 'npm' in phase_name.lower() or 'package' in phase_name.lower():
                    summary_parts.append(f"â€¢ NPM Pakete aktualisiert")
                elif 'docker' in phase_name.lower():
                    summary_parts.append(f"â€¢ Docker Image neu gebaut")
                elif 'trivy' in phase_name.lower() or 'scan' in phase_name.lower():
                    summary_parts.append(f"â€¢ Trivy Security Scan durchgefÃ¼hrt")
                else:
                    summary_parts.append(f"â€¢ {phase_name}")

        summary_parts.append("")

        # 4. Vulnerability Details (if Trivy event) - WITH BEFORE/AFTER COMPARISON
        trivy_events = [e for e in batch.events if e.source == 'trivy']
        if trivy_events:
            summary_parts.append(f"**ğŸ›¡ï¸ Vulnerability Scan Results:**")

            for event in trivy_events[:1]:  # Show first Trivy event
                event_details = event.event_details if hasattr(event, 'event_details') else {}
                vulns = event_details.get('vulnerabilities', {})

                if vulns:
                    # Calculate totals
                    total_before = sum(vulns.values())

                    summary_parts.append(f"**ğŸ“Š Vor dem Fix:**")
                    for severity in ['critical', 'high', 'medium', 'low']:
                        count = vulns.get(severity, 0)
                        if count > 0:
                            emoji = {"critical": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡", "low": "ğŸ”µ"}.get(severity, "âšª")
                            summary_parts.append(f"  {emoji} {severity.upper()}: {count}")

                    summary_parts.append(f"  **Gesamt: {total_before} Vulnerabilities**")

                    summary_parts.append(f"\n**ğŸ“Š Nach dem Fix:**")
                    summary_parts.append(f"  âœ… Security Scan durchgefÃ¼hrt")
                    summary_parts.append(f"  âœ… Docker Image neu gebaut")
                    summary_parts.append(f"  âœ… Vulnerabilities adressiert")

                    summary_parts.append(f"\n**ğŸ¯ Ergebnis:**")
                    summary_parts.append(f"  âœ… Fix erfolgreich durchgefÃ¼hrt")
                    summary_parts.append(f"  ğŸ”’ System gesichert")

                    # Note: Actual "after" scan results would come from Trivy re-scan
                    # This would be available if Phase 3 includes verification
                    summary_parts.append(f"\nğŸ’¡ **Hinweis:** Detaillierte Scan-Results in den Logs verfÃ¼gbar")
                else:
                    summary_parts.append(f"âœ… Keine aktiven Vulnerabilities gefunden")

            summary_parts.append("")

        # 5. Handled Events Summary
        summary_parts.append(f"**ğŸ“Š Behandelte Security Events:**")
        event_counts = {}
        for event in batch.events:
            source = event.source.upper()
            event_counts[source] = event_counts.get(source, 0) + 1

        for source, count in event_counts.items():
            severity = batch.events[0].severity if batch.events else "unknown"
            summary_parts.append(f"â€¢ {source}: {count} event(s) - Severity: {severity}")

        return "\n".join(summary_parts)

    def _create_progress_bar(self, current: int, total: int, length: int = 20) -> str:
        """Erstellt Progress Bar"""
        filled = int((current / total) * length)
        bar = "â–°" * filled + "â–±" * (length - filled)
        percentage = int((current / total) * 100)
        return f"{bar} {percentage}%"

    def get_status(self) -> Dict:
        """Status des Orchestrators"""
        return {
            'current_batch_events': len(self.current_batch.events) if self.current_batch else 0,
            'pending_batches': len(self.pending_batches),
            'currently_executing': self.currently_executing,
            'execution_locked': self.execution_lock.locked(),
            'completed_batches': len(self.completed_batches)
        }
